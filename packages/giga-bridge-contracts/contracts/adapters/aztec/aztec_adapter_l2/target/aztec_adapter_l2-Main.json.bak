{"noir_version":"1.0.0-beta.11+5b65f9637e85a4177692c3190cb35ea678fb15e9-aztec","name":"Main","functions":[{"name":"initialize","hash":"10515589610316405905","is_unconstrained":true,"custom_attributes":["public"],"abi":{"parameters":[{"name":"aztec_l1_adapter","type":{"kind":"struct","path":"aztec::protocol_types::address::eth_address::EthAddress","fields":[{"name":"inner","type":{"kind":"field"}}]},"visibility":"private"}],"return_type":null,"error_types":{"17843811134343075018":{"error_kind":"string","string":"Stack too deep"}}},"bytecode":"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","debug_symbols":"tZndbhs5DIXfxde+kERSP32VRVGkqVsEMJLATRZYFHn3JYc8dtxiBK+dvcn5kswcixyK1MC/Nt92X19/fHl4/P70c/Ppr1+br4eH/f7hx5f90/3dy8PTo/711ybZjyybT327ydWluXSXsUhJLtmluJALu7hLcZeiLkOlu4xFKLlkl+JCLuwiLtXFXchdyF3YXVhdmkpxIRd2EZfq0ly6y1hEkou7iLuIu4i7iF6Z83ZTU2gOLaEUyqESWkNbaA8Nv2Z+RTWHllAKtft4u+l2najm0BJKoRwqofa5uu7eQnvocB0pNIeWUAo1P312Q0JraAvtocM1JzMcBhlQAARQs5IMKqAB1K9kgxGQEyADIqc5V0ADdEDkNZcEyIBIbS4EYIAAhqc7U+Q3EwEYIIAKaIDIcqZIc+YEyIACIAADBBDZztwAHYCEW9E6ZAASLki4Fa+DACzhZGAJt0itshew0nbIAL29VAO7yxZm5eswAqyAHTKgAHQZxT60MUAAFdAAHTACrOQdzNnSa0XvQAAGCECdySrKKt9BnclCttonM7Tid8iAAiAAAwRQAQ3QAeFcUgJkQAGY89I+GSCACmiADhgBth0c1JmzQQEQgAECqIAG6IARYDvFAc62U7gYEIABAjAfscZvd1WDAiAAAwRQAbaeZW50wAiwLeOQAQVAAAaYMxtUQAN0gDnbI7At46DOQgYFQACJuKQCGgAh25YRc64IuSLkipBtAIhdbBPAoQHUR5ZrRlxsm8gByWxwbnBucG5IZkMybRM5dACcOwx77OWy7JQFKqABbGHNRnTs5TIKgADqI5Z52xcOFWABLhO+4+LoEpQSIAMKgAAMEEAFNEA4U4ahFb91bLLidxBABejtNdkpI6YolQwoAPWp2YABAlCfWgwaLu6AEUBwJjhjghAmCGGCECYIYYIQJggRDJcxYYtnBMgIkBGg1fwSF+MuwTIEy7AKX6IQBCgI0Ep9iUuwDMEyBAEKnCucK5wrAqwIsCLAigArnJdzj7y9bTc4c355Oex2duR8dwjVo+nz3WH3+LL59Pi63283f9/tX5eLfj7fPS76cnfQ/2rQu8dvqmr4/WG/M3rbnu5O67fqTJW4W0fnyUDOHfK6g1Qp4SC1j6ODDqEzi7JuwdoJw4I1basWtG7R6kAcrVE5WmjZn1nwxIJtLroF97RqIesWdEwF600wKOXcoK4b6BzK4aCTaKxatMnzsFOCPw5KVxmMFgZVa/SaIErHEop2tlWLPKtLKelYl9yu9Kjj6NHHdR6Ujh7a6NY9ZrXJ5VhX9SqHwSjuIdetQd8/sAh931h/rHnyXJkripN5nNaRx39Ip51BIp1y5WOlY4Eq9qs8PiKUTMcK1ReSqzZKy+h7erJZ36yl/L8eudZjKLX16zy07cKjjfVNX+TWjTJzuGyjzBwu3Sil31xd03SOU98ZZdJDJ328JaxC2rvW9cdUzbOnSnLcsI3aqYnW81hoEoue8BJqQ5lkzWQazECZS383W/8IhmeP9tR8Un1XYL89F5LbDwlUbz0lULv9mED91jE/XcWFc54/YM7zB8z5aSwXtlGm21sg860tcOZwWQtkvr0Fcru5BU7T+REtUNKxBbb1riGT6tLX5I506Jty4rXuJZOF6Pu4IBg6e9H63WTWR4WPc1pfV1NeM5mWR8K2H+XKAqtIx2hya4lOHKZz/qIopg4XRXHhWWPiMD3WXxTF1OGiKC58tfjd4bP+enf/cDj7YuzNrA4Pd1/3u/j1++vj/bv/vvzzjP/gi7Xnw9P97tvrYWdOp2/X9Mdf1NpWD/Gf7buO5de8pVY/v9mn/ws=","expression_width":{"Bounded":{"width":4}}},{"name":"receive_root","hash":"1175922122568071351","is_unconstrained":true,"custom_attributes":["public"],"abi":{"parameters":[{"name":"root","type":{"kind":"field"},"visibility":"private"},{"name":"root_type","type":{"kind":"integer","sign":"unsigned","width":8},"visibility":"private"},{"name":"bridge_message_leaf_index","type":{"kind":"field"},"visibility":"private"}],"return_type":null,"error_types":{"206160798890201757":{"error_kind":"string","string":"Storage slot 0 not allowed. Storage slots must start from 1."},"2550444873539515884":{"error_kind":"string","string":"Trying to read from uninitialized PublicImmutable"},"2920182694213909827":{"error_kind":"string","string":"attempt to subtract with overflow"},"5019202896831570965":{"error_kind":"string","string":"attempt to add with overflow"},"7043145299448266897":{"error_kind":"string","string":"L1-to-L2 message is already nullified"},"7233212735005103307":{"error_kind":"string","string":"attempt to multiply with overflow"},"13293000217372736598":{"error_kind":"string","string":"Tried to consume nonexistent L1-to-L2 message"},"14156770082850582201":{"error_kind":"string","string":"invalid root type"},"14225679739041873922":{"error_kind":"string","string":"Index out of bounds"},"17843811134343075018":{"error_kind":"string","string":"Stack too deep"}}},"bytecode":"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","debug_symbols":"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","expression_width":{"Bounded":{"width":4}}},{"name":"update_leaf","hash":"8752886959610227721","is_unconstrained":true,"custom_attributes":["public"],"abi":{"parameters":[{"name":"leaf_index","type":{"kind":"integer","sign":"unsigned","width":128},"visibility":"private"},{"name":"leaf_value","type":{"kind":"field"},"visibility":"private"}],"return_type":null,"error_types":{"2550444873539515884":{"error_kind":"string","string":"Trying to read from uninitialized PublicImmutable"},"5019202896831570965":{"error_kind":"string","string":"attempt to add with overflow"},"14225679739041873922":{"error_kind":"string","string":"Index out of bounds"},"17843811134343075018":{"error_kind":"string","string":"Stack too deep"}}},"bytecode":"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","debug_symbols":"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","expression_width":{"Bounded":{"width":4}}}],"outputs":{"structs":{"functions":[{"kind":"struct","path":"Main::initialize_abi","fields":[{"name":"parameters","type":{"kind":"struct","path":"Main::initialize_parameters","fields":[{"name":"aztec_l1_adapter","type":{"kind":"struct","path":"aztec::protocol_types::address::eth_address::EthAddress","fields":[{"name":"inner","type":{"kind":"field"}}]}}]}}]},{"kind":"struct","path":"Main::receive_root_abi","fields":[{"name":"parameters","type":{"kind":"struct","path":"Main::receive_root_parameters","fields":[{"name":"root","type":{"kind":"field"}},{"name":"root_type","type":{"kind":"integer","sign":"unsigned","width":8}},{"name":"bridge_message_leaf_index","type":{"kind":"field"}}]}}]},{"kind":"struct","path":"Main::update_leaf_abi","fields":[{"name":"parameters","type":{"kind":"struct","path":"Main::update_leaf_parameters","fields":[{"name":"leaf_index","type":{"kind":"integer","sign":"unsigned","width":128}},{"name":"leaf_value","type":{"kind":"field"}}]}}]}]},"globals":{"storage":[{"kind":"struct","fields":[{"name":"contract_name","value":{"kind":"string","value":"Main"}},{"name":"fields","value":{"kind":"struct","fields":[{"name":"aztec_l1_adapter","value":{"kind":"struct","fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000001"}}]}},{"name":"owner_of_leaf_index","value":{"kind":"struct","fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000003"}}]}},{"name":"root_history","value":{"kind":"struct","fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000004"}}]}},{"name":"giga_root","value":{"kind":"struct","fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000005"}}]}}]}}]}]}},"file_map":{"3":{"source":"use crate::cmp::{Eq, Ord};\nuse crate::convert::From;\nuse crate::runtime::is_unconstrained;\n\nmod check_shuffle;\nmod quicksort;\n\nimpl<T, let N: u32> [T; N] {\n    /// Returns the length of this array.\n    ///\n    /// ```noir\n    /// fn len(self) -> Field\n    /// ```\n    ///\n    /// example\n    ///\n    /// ```noir\n    /// fn main() {\n    ///     let array = [42, 42];\n    ///     assert(array.len() == 2);\n    /// }\n    /// ```\n    #[builtin(array_len)]\n    pub fn len(self) -> u32 {}\n\n    /// Returns this array as a slice.\n    ///\n    /// ```noir\n    /// let array = [1, 2];\n    /// let slice = array.as_slice();\n    /// assert_eq(slice, &[1, 2]);\n    /// ```\n    #[builtin(as_slice)]\n    pub fn as_slice(self) -> [T] {}\n\n    /// Applies a function to each element of this array, returning a new array containing the mapped elements.\n    ///\n    /// Example:\n    ///\n    /// ```rust\n    /// let a = [1, 2, 3];\n    /// let b = a.map(|a| a * 2);\n    /// assert_eq(b, [2, 4, 6]);\n    /// ```\n    pub fn map<U, Env>(self, f: fn[Env](T) -> U) -> [U; N] {\n        let uninitialized = crate::mem::zeroed();\n        let mut ret = [uninitialized; N];\n\n        for i in 0..self.len() {\n            ret[i] = f(self[i]);\n        }\n\n        ret\n    }\n\n    /// Applies a function to each element of this array along with its index,\n    /// returning a new array containing the mapped elements.\n    ///\n    /// Example:\n    ///\n    /// ```rust\n    /// let a = [1, 2, 3];\n    /// let b = a.mapi(|i, a| i + a * 2);\n    /// assert_eq(b, [2, 5, 8]);\n    /// ```\n    pub fn mapi<U, Env>(self, f: fn[Env](u32, T) -> U) -> [U; N] {\n        let uninitialized = crate::mem::zeroed();\n        let mut ret = [uninitialized; N];\n\n        for i in 0..self.len() {\n            ret[i] = f(i, self[i]);\n        }\n\n        ret\n    }\n\n    /// Applies a function to each element of this array.\n    ///\n    /// Example:\n    ///\n    /// ```rust\n    /// let a = [1, 2, 3];\n    /// let mut b = [0; 3];\n    /// let mut i = 0;\n    /// a.for_each(|x| {\n    ///     b[i] = x;\n    ///     i += 1;\n    /// });\n    /// assert_eq(a, b);\n    /// ```\n    pub fn for_each<Env>(self, f: fn[Env](T) -> ()) {\n        for i in 0..self.len() {\n            f(self[i]);\n        }\n    }\n\n    /// Applies a function to each element of this array along with its index.\n    ///\n    /// Example:\n    ///\n    /// ```rust\n    /// let a = [1, 2, 3];\n    /// let mut b = [0; 3];\n    /// a.for_eachi(|i, x| {\n    ///     b[i] = x;\n    /// });\n    /// assert_eq(a, b);\n    /// ```\n    pub fn for_eachi<Env>(self, f: fn[Env](u32, T) -> ()) {\n        for i in 0..self.len() {\n            f(i, self[i]);\n        }\n    }\n\n    /// Applies a function to each element of the array, returning the final accumulated value. The first\n    /// parameter is the initial value.\n    ///\n    /// This is a left fold, so the given function will be applied to the accumulator and first element of\n    /// the array, then the second, and so on. For a given call the expected result would be equivalent to:\n    ///\n    /// ```rust\n    /// let a1 = [1];\n    /// let a2 = [1, 2];\n    /// let a3 = [1, 2, 3];\n    ///\n    /// let f = |a, b| a - b;\n    /// a1.fold(10, f); //=> f(10, 1)\n    /// a2.fold(10, f); //=> f(f(10, 1), 2)\n    /// a3.fold(10, f); //=> f(f(f(10, 1), 2), 3)\n    ///\n    /// assert_eq(a3.fold(10, f), 10 - 1 - 2 - 3);\n    /// ```\n    pub fn fold<U, Env>(self, mut accumulator: U, f: fn[Env](U, T) -> U) -> U {\n        for elem in self {\n            accumulator = f(accumulator, elem);\n        }\n        accumulator\n    }\n\n    /// Same as fold, but uses the first element as the starting element.\n    ///\n    /// Requires the input array to be non-empty.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn main() {\n    ///     let arr = [1, 2, 3, 4];\n    ///     let reduced = arr.reduce(|a, b| a + b);\n    ///     assert(reduced == 10);\n    /// }\n    /// ```\n    pub fn reduce<Env>(self, f: fn[Env](T, T) -> T) -> T {\n        let mut accumulator = self[0];\n        for i in 1..self.len() {\n            accumulator = f(accumulator, self[i]);\n        }\n        accumulator\n    }\n\n    /// Returns true if all the elements in this array satisfy the given predicate.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn main() {\n    ///     let arr = [2, 2, 2, 2, 2];\n    ///     let all = arr.all(|a| a == 2);\n    ///     assert(all);\n    /// }\n    /// ```\n    pub fn all<Env>(self, predicate: fn[Env](T) -> bool) -> bool {\n        let mut ret = true;\n        for elem in self {\n            ret &= predicate(elem);\n        }\n        ret\n    }\n\n    /// Returns true if any of the elements in this array satisfy the given predicate.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn main() {\n    ///     let arr = [2, 2, 2, 2, 5];\n    ///     let any = arr.any(|a| a == 5);\n    ///     assert(any);\n    /// }\n    /// ```\n    pub fn any<Env>(self, predicate: fn[Env](T) -> bool) -> bool {\n        let mut ret = false;\n        for elem in self {\n            ret |= predicate(elem);\n        }\n        ret\n    }\n\n    /// Concatenates this array with another array.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn main() {\n    ///     let arr1 = [1, 2, 3, 4];\n    ///     let arr2 = [6, 7, 8, 9, 10, 11];\n    ///     let concatenated_arr = arr1.concat(arr2);\n    ///     assert(concatenated_arr == [1, 2, 3, 4, 6, 7, 8, 9, 10, 11]);\n    /// }\n    /// ```\n    pub fn concat<let M: u32>(self, array2: [T; M]) -> [T; N + M] {\n        let mut result = [crate::mem::zeroed(); N + M];\n        for i in 0..N {\n            result[i] = self[i];\n        }\n        for i in 0..M {\n            result[i + N] = array2[i];\n        }\n        result\n    }\n}\n\nimpl<T, let N: u32> [T; N]\nwhere\n    T: Ord + Eq,\n{\n    /// Returns a new sorted array. The original array remains untouched. Notice that this function will\n    /// only work for arrays of fields or integers, not for any arbitrary type. This is because the sorting\n    /// logic it uses internally is optimized specifically for these values. If you need a sort function to\n    /// sort any type, you should use the `sort_via` function.\n    ///\n    /// Example:\n    ///\n    /// ```rust\n    /// fn main() {\n    ///     let arr = [42, 32];\n    ///     let sorted = arr.sort();\n    ///     assert(sorted == [32, 42]);\n    /// }\n    /// ```\n    pub fn sort(self) -> Self {\n        self.sort_via(|a, b| a <= b)\n    }\n}\n\nimpl<T, let N: u32> [T; N]\nwhere\n    T: Eq,\n{\n    /// Returns a new sorted array by sorting it with a custom comparison function.\n    /// The original array remains untouched.\n    /// The ordering function must return true if the first argument should be sorted to be before the second argument or is equal to the second argument.\n    ///\n    /// Using this method with an operator like `<` that does not return `true` for equal values will result in an assertion failure for arrays with equal elements.\n    ///\n    /// Example:\n    ///\n    /// ```rust\n    /// fn main() {\n    ///     let arr = [42, 32]\n    ///     let sorted_ascending = arr.sort_via(|a, b| a <= b);\n    ///     assert(sorted_ascending == [32, 42]); // verifies\n    ///\n    ///     let sorted_descending = arr.sort_via(|a, b| a >= b);\n    ///     assert(sorted_descending == [32, 42]); // does not verify\n    /// }\n    /// ```\n    pub fn sort_via<Env>(self, ordering: fn[Env](T, T) -> bool) -> Self {\n        // Safety: `sorted` array is checked to be:\n        // a. a permutation of `input`'s elements\n        // b. satisfying the predicate `ordering`\n        let sorted = unsafe { quicksort::quicksort(self, ordering) };\n\n        if !is_unconstrained() {\n            for i in 0..N - 1 {\n                assert(\n                    ordering(sorted[i], sorted[i + 1]),\n                    \"Array has not been sorted correctly according to `ordering`.\",\n                );\n            }\n            check_shuffle::check_shuffle(self, sorted);\n        }\n        sorted\n    }\n}\n\nimpl<let N: u32> [u8; N] {\n    /// Converts a byte array of type `[u8; N]` to a string. Note that this performs no UTF-8 validation -\n    /// the given array is interpreted as-is as a string.\n    ///\n    /// Example:\n    ///\n    /// ```rust\n    /// fn main() {\n    ///     let hi = [104, 105].as_str_unchecked();\n    ///     assert_eq(hi, \"hi\");\n    /// }\n    /// ```\n    #[builtin(array_as_str_unchecked)]\n    pub fn as_str_unchecked(self) -> str<N> {}\n}\n\nimpl<let N: u32> From<str<N>> for [u8; N] {\n    /// Returns an array of the string bytes.\n    fn from(s: str<N>) -> Self {\n        s.as_bytes()\n    }\n}\n\nmod test {\n    #[test]\n    fn map_empty() {\n        assert_eq([].map(|x| x + 1), []);\n    }\n\n    global arr_with_100_values: [u32; 100] = [\n        42, 123, 87, 93, 48, 80, 50, 5, 104, 84, 70, 47, 119, 66, 71, 121, 3, 29, 42, 118, 2, 54,\n        89, 44, 81, 0, 26, 106, 68, 96, 84, 48, 95, 54, 45, 32, 89, 100, 109, 19, 37, 41, 19, 98,\n        53, 114, 107, 66, 6, 74, 13, 19, 105, 64, 123, 28, 44, 50, 89, 58, 123, 126, 21, 43, 86, 35,\n        21, 62, 82, 0, 108, 120, 72, 72, 62, 80, 12, 71, 70, 86, 116, 73, 38, 15, 127, 81, 30, 8,\n        125, 28, 26, 69, 114, 63, 27, 28, 61, 42, 13, 32,\n    ];\n    global expected_with_100_values: [u32; 100] = [\n        0, 0, 2, 3, 5, 6, 8, 12, 13, 13, 15, 19, 19, 19, 21, 21, 26, 26, 27, 28, 28, 28, 29, 30, 32,\n        32, 35, 37, 38, 41, 42, 42, 42, 43, 44, 44, 45, 47, 48, 48, 50, 50, 53, 54, 54, 58, 61, 62,\n        62, 63, 64, 66, 66, 68, 69, 70, 70, 71, 71, 72, 72, 73, 74, 80, 80, 81, 81, 82, 84, 84, 86,\n        86, 87, 89, 89, 89, 93, 95, 96, 98, 100, 104, 105, 106, 107, 108, 109, 114, 114, 116, 118,\n        119, 120, 121, 123, 123, 123, 125, 126, 127,\n    ];\n    fn sort_u32(a: u32, b: u32) -> bool {\n        a <= b\n    }\n\n    #[test]\n    fn test_sort() {\n        let mut arr: [u32; 7] = [3, 6, 8, 10, 1, 2, 1];\n\n        let sorted = arr.sort();\n\n        let expected: [u32; 7] = [1, 1, 2, 3, 6, 8, 10];\n        assert(sorted == expected);\n    }\n\n    #[test]\n    fn test_sort_100_values() {\n        let mut arr: [u32; 100] = [\n            42, 123, 87, 93, 48, 80, 50, 5, 104, 84, 70, 47, 119, 66, 71, 121, 3, 29, 42, 118, 2,\n            54, 89, 44, 81, 0, 26, 106, 68, 96, 84, 48, 95, 54, 45, 32, 89, 100, 109, 19, 37, 41,\n            19, 98, 53, 114, 107, 66, 6, 74, 13, 19, 105, 64, 123, 28, 44, 50, 89, 58, 123, 126, 21,\n            43, 86, 35, 21, 62, 82, 0, 108, 120, 72, 72, 62, 80, 12, 71, 70, 86, 116, 73, 38, 15,\n            127, 81, 30, 8, 125, 28, 26, 69, 114, 63, 27, 28, 61, 42, 13, 32,\n        ];\n\n        let sorted = arr.sort();\n\n        let expected: [u32; 100] = [\n            0, 0, 2, 3, 5, 6, 8, 12, 13, 13, 15, 19, 19, 19, 21, 21, 26, 26, 27, 28, 28, 28, 29, 30,\n            32, 32, 35, 37, 38, 41, 42, 42, 42, 43, 44, 44, 45, 47, 48, 48, 50, 50, 53, 54, 54, 58,\n            61, 62, 62, 63, 64, 66, 66, 68, 69, 70, 70, 71, 71, 72, 72, 73, 74, 80, 80, 81, 81, 82,\n            84, 84, 86, 86, 87, 89, 89, 89, 93, 95, 96, 98, 100, 104, 105, 106, 107, 108, 109, 114,\n            114, 116, 118, 119, 120, 121, 123, 123, 123, 125, 126, 127,\n        ];\n        assert(sorted == expected);\n    }\n\n    #[test]\n    fn test_sort_100_values_comptime() {\n        let sorted = arr_with_100_values.sort();\n        assert(sorted == expected_with_100_values);\n    }\n\n    #[test]\n    fn test_sort_via() {\n        let mut arr: [u32; 7] = [3, 6, 8, 10, 1, 2, 1];\n\n        let sorted = arr.sort_via(sort_u32);\n\n        let expected: [u32; 7] = [1, 1, 2, 3, 6, 8, 10];\n        assert(sorted == expected);\n    }\n\n    #[test]\n    fn test_sort_via_100_values() {\n        let mut arr: [u32; 100] = [\n            42, 123, 87, 93, 48, 80, 50, 5, 104, 84, 70, 47, 119, 66, 71, 121, 3, 29, 42, 118, 2,\n            54, 89, 44, 81, 0, 26, 106, 68, 96, 84, 48, 95, 54, 45, 32, 89, 100, 109, 19, 37, 41,\n            19, 98, 53, 114, 107, 66, 6, 74, 13, 19, 105, 64, 123, 28, 44, 50, 89, 58, 123, 126, 21,\n            43, 86, 35, 21, 62, 82, 0, 108, 120, 72, 72, 62, 80, 12, 71, 70, 86, 116, 73, 38, 15,\n            127, 81, 30, 8, 125, 28, 26, 69, 114, 63, 27, 28, 61, 42, 13, 32,\n        ];\n\n        let sorted = arr.sort_via(sort_u32);\n\n        let expected: [u32; 100] = [\n            0, 0, 2, 3, 5, 6, 8, 12, 13, 13, 15, 19, 19, 19, 21, 21, 26, 26, 27, 28, 28, 28, 29, 30,\n            32, 32, 35, 37, 38, 41, 42, 42, 42, 43, 44, 44, 45, 47, 48, 48, 50, 50, 53, 54, 54, 58,\n            61, 62, 62, 63, 64, 66, 66, 68, 69, 70, 70, 71, 71, 72, 72, 73, 74, 80, 80, 81, 81, 82,\n            84, 84, 86, 86, 87, 89, 89, 89, 93, 95, 96, 98, 100, 104, 105, 106, 107, 108, 109, 114,\n            114, 116, 118, 119, 120, 121, 123, 123, 123, 125, 126, 127,\n        ];\n        assert(sorted == expected);\n    }\n\n    #[test]\n    fn mapi_empty() {\n        assert_eq([].mapi(|i, x| i * x + 1), []);\n    }\n\n    #[test]\n    fn for_each_empty() {\n        let empty_array: [Field; 0] = [];\n        empty_array.for_each(|_x| assert(false));\n    }\n\n    #[test]\n    fn for_eachi_empty() {\n        let empty_array: [Field; 0] = [];\n        empty_array.for_eachi(|_i, _x| assert(false));\n    }\n\n    #[test]\n    fn map_example() {\n        let a = [1, 2, 3];\n        let b = a.map(|a| a * 2);\n        assert_eq(b, [2, 4, 6]);\n    }\n\n    #[test]\n    fn mapi_example() {\n        let a = [1, 2, 3];\n        let b = a.mapi(|i, a| i + a * 2);\n        assert_eq(b, [2, 5, 8]);\n    }\n\n    #[test]\n    fn for_each_example() {\n        let a = [1, 2, 3];\n        let mut b = [0, 0, 0];\n        let b_ref = &mut b;\n        let mut i = 0;\n        let i_ref = &mut i;\n        a.for_each(|x| {\n            b_ref[*i_ref] = x * 2;\n            *i_ref += 1;\n        });\n        assert_eq(b, [2, 4, 6]);\n        assert_eq(i, 3);\n    }\n\n    #[test]\n    fn for_eachi_example() {\n        let a = [1, 2, 3];\n        let mut b = [0, 0, 0];\n        let b_ref = &mut b;\n        a.for_eachi(|i, a| { b_ref[i] = i + a * 2; });\n        assert_eq(b, [2, 5, 8]);\n    }\n\n    #[test]\n    fn concat() {\n        let arr1 = [1, 2, 3, 4];\n        let arr2 = [6, 7, 8, 9, 10, 11];\n        let concatenated_arr = arr1.concat(arr2);\n        assert_eq(concatenated_arr, [1, 2, 3, 4, 6, 7, 8, 9, 10, 11]);\n    }\n\n    #[test]\n    fn concat_zero_length_with_something() {\n        let arr1 = [];\n        let arr2 = [1];\n        let concatenated_arr = arr1.concat(arr2);\n        assert_eq(concatenated_arr, [1]);\n    }\n\n    #[test]\n    fn concat_something_with_zero_length() {\n        let arr1 = [1];\n        let arr2 = [];\n        let concatenated_arr = arr1.concat(arr2);\n        assert_eq(concatenated_arr, [1]);\n    }\n\n    #[test]\n    fn concat_zero_lengths() {\n        let arr1: [Field; 0] = [];\n        let arr2: [Field; 0] = [];\n        let concatenated_arr = arr1.concat(arr2);\n        assert_eq(concatenated_arr, []);\n    }\n}\n","path":"std/array/mod.nr"},"18":{"source":"pub mod bn254;\nuse crate::{runtime::is_unconstrained, static_assert};\nuse bn254::lt as bn254_lt;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size<let BIT_SIZE: u32>(self) {\n        // docs:end:assert_max_bit_size\n        static_assert(\n            BIT_SIZE < modulus_num_bits() as u32,\n            \"BIT_SIZE must be less than modulus_num_bits\",\n        );\n        __assert_max_bit_size(self, BIT_SIZE);\n    }\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_le_bits\n        let bits = __to_le_bits(self);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[N - 1 - i] != p[N - 1 - i]) {\n                        assert(p[N - 1 - i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_be_bits\n        let bits = __to_be_bits(self);\n\n        if !is_unconstrained() {\n            // Ensure that the decomposition does not overflow the modulus\n            let p = modulus_be_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[i] != p[i]) {\n                        assert(p[i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        __to_le_radix(self, radix)\n    }\n\n    fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        __to_be_radix(self, radix)\n    }\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32 - i] as Field) * (r * self) + (1 - b[32 - i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N - 1 - i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(apply_range_constraint)]\nfn __assert_max_bit_size(value: Field, bit_size: u32) {}\n\n// `_radix` must be less than 256\n#[builtin(to_le_radix)]\nfn __to_le_radix<let N: u32>(value: Field, radix: u32) -> [u8; N] {}\n\n// `_radix` must be less than 256\n#[builtin(to_be_radix)]\nfn __to_be_radix<let N: u32>(value: Field, radix: u32) -> [u8; N] {}\n\n/// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n/// This slice will be zero padded should not all bits be necessary to represent `self`.\n///\n/// # Failures\n/// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n/// be able to represent the original `Field`.\n///\n/// # Safety\n/// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n/// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n/// wrap around due to overflow when verifying the decomposition.\n#[builtin(to_le_bits)]\nfn __to_le_bits<let N: u32>(value: Field) -> [u1; N] {}\n\n/// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n/// This array will be zero padded should not all bits be necessary to represent `self`.\n///\n/// # Failures\n/// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n/// be able to represent the original `Field`.\n///\n/// # Safety\n/// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n/// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n/// wrap around due to overflow when verifying the decomposition.\n#[builtin(to_be_bits)]\nfn __to_be_bits<let N: u32>(value: Field) -> [u1; N] {}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n/// An unconstrained only built in to efficiently compare fields.\n#[builtin(field_less_than)]\nunconstrained fn __field_less_than(x: Field, y: Field) -> bool {}\n\npub(crate) unconstrained fn field_less_than(x: Field, y: Field) -> bool {\n    __field_less_than(x, y)\n}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unconstrained context\n        unsafe {\n            field_less_than(x, y)\n        }\n    } else {\n        let x_bytes: [u8; 32] = x.to_le_bytes();\n        let y_bytes: [u8; 32] = y.to_le_bytes();\n        let mut x_is_lt = false;\n        let mut done = false;\n        for i in 0..32 {\n            if (!done) {\n                let x_byte = x_bytes[32 - 1 - i] as u8;\n                let y_byte = y_bytes[32 - 1 - i] as u8;\n                let bytes_match = x_byte == y_byte;\n                if !bytes_match {\n                    x_is_lt = x_byte < y_byte;\n                    done = true;\n                }\n            }\n        }\n        x_is_lt\n    }\n}\n\nmod tests {\n    use crate::{panic::panic, runtime};\n    use super::field_less_than;\n\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_be_bytes();\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_le_bytes();\n        assert_eq(bytes, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        // 259, in base 256, big endian, is [1, 3].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 1, 3]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        // 259, in base 256, little endian, is [3, 1].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bytes, [3, 1, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_radix_example\n\n    #[test(should_fail_with = \"radix must be greater than 1\")]\n    fn test_to_le_radix_1() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(1);\n        } else {\n            panic(f\"radix must be greater than 1\");\n        }\n    }\n\n    // TODO: Update this test to account for the Brillig restriction that the radix must be greater than 2\n    //#[test]\n    //fn test_to_le_radix_brillig_1() {\n    //    // this test should only fail in constrained mode\n    //    if runtime::is_unconstrained() {\n    //        let field = 1;\n    //        let out: [u8; 8] = field.to_le_radix(1);\n    //        crate::println(out);\n    //        let expected = [0; 8];\n    //        assert(out == expected, \"unexpected result\");\n    //    }\n    //}\n\n    #[test(should_fail_with = \"radix must be a power of 2\")]\n    fn test_to_le_radix_3() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(3);\n        } else {\n            panic(f\"radix must be a power of 2\");\n        }\n    }\n\n    #[test]\n    fn test_to_le_radix_brillig_3() {\n        // this test should only fail in constrained mode\n        if runtime::is_unconstrained() {\n            let field = 1;\n            let out: [u8; 8] = field.to_le_radix(3);\n            let mut expected = [0; 8];\n            expected[0] = 1;\n            assert(out == expected, \"unexpected result\");\n        }\n    }\n\n    #[test(should_fail_with = \"radix must be less than or equal to 256\")]\n    fn test_to_le_radix_512() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(512);\n        } else {\n            panic(f\"radix must be less than or equal to 256\")\n        }\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 16 limbs\")]\n    unconstrained fn not_enough_limbs_brillig() {\n        let _: [u8; 16] = 0x100000000000000000000000000000000.to_le_bytes();\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 16 limbs\")]\n    fn not_enough_limbs() {\n        let _: [u8; 16] = 0x100000000000000000000000000000000.to_le_bytes();\n    }\n\n    // TODO: Update this test to account for the Brillig restriction that the radix must be less than 512\n    //#[test]\n    //fn test_to_le_radix_brillig_512() {\n    //    // this test should only fail in constrained mode\n    //    if runtime::is_unconstrained() {\n    //        let field = 1;\n    //        let out: [u8; 8] = field.to_le_radix(512);\n    //        let mut expected = [0; 8];\n    //        expected[0] = 1;\n    //        assert(out == expected, \"unexpected result\");\n    //    }\n    //}\n\n    #[test]\n    unconstrained fn test_field_less_than() {\n        assert(field_less_than(0, 1));\n        assert(field_less_than(0, 0x100));\n        assert(field_less_than(0x100, 0 - 1));\n        assert(!field_less_than(0 - 1, 0));\n    }\n}\n","path":"std/field/mod.nr"},"19":{"source":"// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{\n    if crate::runtime::is_unconstrained() {\n        // Temporary measure while Barretenberg is main proving system.\n        // Please open an issue if you're working on another proving system and running into problems due to this.\n        crate::static_assert(\n            N <= 1024,\n            \"Barretenberg cannot prove blake3 hashes with inputs larger than 1024 bytes\",\n        );\n    }\n    __blake3(input)\n}\n\n#[foreign(blake3)]\nfn __blake3<let N: u32>(input: [u8; N]) -> [u8; 32] {}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars, true)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Same as from_field but:\n// does not assert the limbs are 128 bits\n// does not assert the decomposition does not overflow the EmbeddedCurveScalar\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn poseidon2_permutation<let N: u32>(input: [Field; N], state_len: u32) -> [Field; N] {\n    assert_eq(input.len(), state_len);\n    poseidon2_permutation_internal(input)\n}\n\n#[foreign(poseidon2_permutation)]\nfn poseidon2_permutation_internal<let N: u32>(input: [Field; N]) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { $crate::hash::Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: $crate::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher {\n    type H: Hasher;\n\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    type H = H;\n\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u8 as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u16 as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u32 as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u64 as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n","path":"std/hash/mod.nr"},"50":{"source":"use dep::aztec::macros::aztec;\n\ncontract Main {\n    use aztec::{\n        context,\n        event::event_interface::{emit_event_in_private, MessageDelivery},\n        oracle::random::random,\n        event::event_interface::{emit_event_in_public},\n        macros::{events::event, functions::{internal, private, public, utility}, storage::storage},\n        note::{note_getter::get_note},\n        state_vars::{PublicImmutable, Map, PublicMutable, storage::HasStorageSlot, private_mutable::PrivateMutable},\n        protocol_types::{\n            hash::poseidon2_hash, abis::block_header::BlockHeader,\n            address::{AztecAddress, EthAddress},\n            storage::map::derive_storage_slot_in_map,\n            traits::Serialize,\n        },\n        utils::{\n            with_hash::WithHash::{self},\n        },\n    };\n\n    //TODO use enums once available\n    global NOT_A_ROOT: u8 = 0; // mappings default to zero, this causes keys not set in rootHistory to default to NOT_A_ROOT\n    global GIGA_ROOT: u8 = 1;\n    global SYNC_ROOT: u8 = 2;\n\n    #[storage]\n    struct Storage<Context> {\n        aztec_l1_adapter: PublicImmutable<EthAddress, Context>,\n        owner_of_leaf_index: Map<AztecAddress, PublicMutable<u128, Context>, Context>,\n        // TODO use enums once available\n        root_history: Map<Field, PublicImmutable<u8, Context>, Context>,\n        giga_root: PublicMutable<Field, Context>\n    }\n\n    #[public]\n    fn initialize(aztec_l1_adapter: EthAddress) {\n        storage.aztec_l1_adapter.initialize(aztec_l1_adapter); \n    }\n\n    #[public]\n    fn update_leaf(leaf_index: u128, leaf_value: Field) {\n        // make sure msg.sender is the contract that is registered on L1\n        // message l1 adapter updateFromL2(leaf_index, leaf_value, msg.sender)\n        let block_number: u32 = context.block_number();\n        let registrant: AztecAddress = context.msg_sender();\n        let content_hash: Field = poseidon2_hash([leaf_index as Field, leaf_value as Field, block_number as Field, registrant.inner]);\n        let aztec_l1_adapter: EthAddress = storage.aztec_l1_adapter.read();\n        context.message_portal(aztec_l1_adapter, content_hash);\n    }\n\n    #[public]\n    fn receive_root(root: Field, root_type: u8, bridge_message_leaf_index: Field) {\n        assert((root_type == GIGA_ROOT) | (root_type == SYNC_ROOT) , \"invalid root type\");\n\n        // no secrets here!\n        let secret: Field = 0;\n        let content_hash: Field = poseidon2_hash([root, root_type as Field]);\n        let aztec_l1_adapter: EthAddress = storage.aztec_l1_adapter.read();\n        context.consume_l1_to_l2_message(content_hash, secret, aztec_l1_adapter, bridge_message_leaf_index);\n        storage.root_history.at(root).initialize(root_type);\n        if (root_type == GIGA_ROOT) {\n            storage.giga_root.write(root);\n        }\n    }\n}\n","path":"/home/jimjim/Desktop/giga-bridge/packages/giga-bridge-contracts/contracts/adapters/aztec/aztec_adapter_l2/src/main.nr"},"69":{"source":"use crate::context::gas::GasOpts;\nuse crate::hash::{\n    compute_l1_to_l2_message_hash, compute_l1_to_l2_message_nullifier, compute_secret_hash,\n};\nuse dep::protocol_types::abis::function_selector::FunctionSelector;\nuse dep::protocol_types::address::{AztecAddress, EthAddress};\nuse dep::protocol_types::constants::MAX_U32_VALUE;\nuse dep::protocol_types::traits::{Empty, FromField, Packable, Serialize, ToField};\n\n/// # PublicContext\n///\n/// The **main interface** between a #[public] function and the Aztec blockchain.\n///\n/// An instance of the PublicContext is initialized automatically at the outset\n/// of every public function, within the #[public] macro, so you'll never\n/// need to consciously instantiate this yourself.\n///\n/// The instance is always named `context`, and it will always be available\n/// within the body of every #[public] function in your smart contract.\n///\n/// Typical usage for a smart contract developer will be to call getter\n/// methods of the PublicContext.\n///\n/// _Pushing_ data and requests to the context is mostly handled within\n/// aztec-nr's own functions, so typically a smart contract developer won't\n/// need to call any setter methods directly.\n///\n/// ## Responsibilities\n/// - Exposes contextual data to a public function:\n///   - Data relating to how this public function was called:\n///     - msg_sender, this_address\n///   - Data relating to the current blockchain state:\n///     - timestamp, block_number, chain_id, version\n///   - Gas and fee information\n/// - Provides state access:\n///   - Read/write public storage (key-value mapping)\n///   - Check existence of notes and nullifiers\n///     (Some patterns use notes & nullifiers to store public (not private)\n///     information)\n///   - Enables consumption of L1->L2 messages.\n/// - Enables calls to other public smart contract functions:\n/// - Writes data to the blockchain:\n///   - Updates to public state variables\n///   - New public logs (for events)\n///   - New L2->L1 messages\n///   - New notes & nullifiers\n///     (E.g. pushing public info to notes/nullifiers, or for completing\n///     \"partial notes\")\n///\n/// ## Key Differences from Private Execution\n///\n/// Unlike private functions -- which are executed on the user's device and which\n/// can only reference historic state -- public functions are executed by a block\n/// proposer and are executed \"live\" on the _current_ tip of the chain.\n/// This means public functions can:\n/// - Read and write _current_ public state\n/// - Immediately see the effects of earlier transactions in the same block\n///\n/// Also, public functions are executed within a zkVM (the \"AVM\"), so that they\n/// can _revert_ whilst still ensuring payment to the proposer and prover.\n/// (Private functions cannot revert: they either succeed, or they cannot be\n/// included).\n///\n/// ## Optimising Public Functions\n///\n/// Using the AVM to execute public functions means they compile down to \"AVM\n/// bytecode\" instead of the ACIR that private functions (standalone circuits)\n/// compile to. Therefore the approach to optimising a public function is\n/// fundamentally different from optimising a public function.\n///\npub struct PublicContext {\n    pub args_hash: Option<Field>,\n    pub compute_args_hash: fn() -> Field,\n}\n\nimpl Eq for PublicContext {\n    fn eq(self, other: Self) -> bool {\n        (self.args_hash == other.args_hash)\n        // Can't compare the function compute_args_hash\n    }\n}\n\nimpl PublicContext {\n    /// Creates a new PublicContext instance.\n    ///\n    /// Low-level function: This is called automatically by the #[public]\n    /// macro, so you shouldn't need to be called directly by smart contract\n    /// developers.\n    ///\n    /// # Arguments\n    /// * `compute_args_hash` - Function to compute the args_hash\n    ///\n    /// # Returns\n    /// * A new PublicContext instance\n    ///\n    pub fn new(compute_args_hash: fn() -> Field) -> Self {\n        PublicContext { args_hash: Option::none(), compute_args_hash }\n    }\n\n    /// Emits a _public_ log that will be visible onchain to everyone.\n    ///\n    /// # Arguments\n    /// * `log` - The data to log, must implement Serialize trait\n    ///\n    pub fn emit_public_log<T>(_self: &mut Self, log: T)\n    where\n        T: Serialize,\n    {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_public_log(Serialize::serialize(log).as_slice()) };\n    }\n\n    /// Checks if a given note hash exists in the note hash tree at a particular\n    /// leaf_index.\n    ///\n    /// # Arguments\n    /// * `note_hash` - The note hash to check for existence\n    /// * `leaf_index` - The index where the note hash should be located\n    ///\n    /// # Returns\n    /// * `bool` - True if the note hash exists at the specified index\n    ///\n    pub fn note_hash_exists(_self: Self, note_hash: Field, leaf_index: u64) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { note_hash_exists(note_hash, leaf_index) } == 1\n    }\n\n    /// Checks if a specific L1-to-L2 message exists in the L1-to-L2 message\n    /// tree at a particular leaf index.\n    ///\n    /// Common use cases include token bridging, cross-chain governance, and\n    /// triggering L2 actions based on L1 events.\n    ///\n    /// This function should be called before attempting to consume an L1-to-L2\n    /// message.\n    ///\n    /// # Arguments\n    /// * `msg_hash` - Hash of the L1-to-L2 message to check\n    /// * `msg_leaf_index` - The index where the message should be located\n    ///\n    /// # Returns\n    /// * `bool` - True if the message exists at the specified index\n    ///\n    /// # Advanced\n    /// * Uses the AVM l1_to_l2_msg_exists opcode for tree lookup\n    /// * Messages are copied from L1 Inbox to L2 by block proposers\n    ///\n    pub fn l1_to_l2_msg_exists(_self: Self, msg_hash: Field, msg_leaf_index: Field) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        // TODO(alvaro): Make l1l2msg leaf index a u64 upstream\n        unsafe { l1_to_l2_msg_exists(msg_hash, msg_leaf_index as u64) } == 1\n    }\n\n    /// Checks if a specific nullifier has been emitted by a given contract.\n    ///\n    /// Whilst nullifiers are primarily intended as a _privacy-preserving_\n    /// record of a one-time action, they can also be used to efficiently\n    /// record _public_ one-time actions too. An example is to check\n    /// whether a contract has been published: we emit a nullifier that is\n    /// deterministic, but whose preimage is _not_ private. This is more\n    /// efficient than using mutable storage, and can be done directly\n    /// from a private function.\n    ///\n    /// Nullifiers can be tested for non-existence in public, which is not the\n    /// case in private. Because private functions do not have access to\n    /// the tip of the blockchain (but only the anchor block they are built\n    /// at) they can only prove nullifier non-existence in the past. But between\n    /// an anchor block and the block in which a tx is included, the nullifier\n    /// might have been inserted into the nullifier tree by some other\n    /// transaction.\n    /// Public functions _do_ have access to the tip of the state, and so\n    /// this pattern is safe.\n    ///\n    /// # Arguments\n    /// * `unsiloed_nullifier` - The raw nullifier value (before siloing with\n    ///                          the contract address that emitted it).\n    /// * `address` - The claimed contract address that emitted the nullifier\n    ///\n    /// # Returns\n    /// * `bool` - True if the nullifier has been emitted by the specified contract\n    ///\n    pub fn nullifier_exists(_self: Self, unsiloed_nullifier: Field, address: AztecAddress) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { nullifier_exists(unsiloed_nullifier, address.to_field()) } == 1\n    }\n\n    /// Consumes a message sent from Ethereum (L1) to Aztec (L2) -- effectively\n    /// marking it as \"read\".\n    ///\n    /// Use this function if you only want the message to ever be \"referred to\"\n    /// once. Once consumed using this method, the message cannot be consumed\n    /// again, because a nullifier is emitted.\n    /// If your use case wants for the message to be read unlimited times, then\n    /// you can always read any historic message from the L1-to-L2 messages tree,\n    /// using the `l1_to_l2_msg_exists` method. Messages never technically get\n    /// deleted from that tree.\n    ///\n    /// The message will first be inserted into an Aztec \"Inbox\" smart contract\n    /// on L1. It will not be available for consumption immediately. Messages\n    /// get copied-over from the L1 Inbox to L2 by the next Proposer in batches.\n    /// So you will need to wait until the messages are copied before you can\n    /// consume them.\n    ///\n    /// # Arguments\n    /// * `content` - The message content that was sent from L1\n    /// * `secret` - Secret value used for message privacy (if needed)\n    /// * `sender` - Ethereum address that sent the message\n    /// * `leaf_index` - Index of the message in the L1-to-L2 message tree\n    ///\n    /// # Advanced\n    /// * Validates message existence in the L1-to-L2 message tree\n    /// * Prevents double-consumption by emitting a nullifier\n    /// * Message hash is computed from all parameters + chain context\n    /// * Will revert if message doesn't exist or was already consumed\n    ///\n    pub fn consume_l1_to_l2_message(\n        &mut self,\n        content: Field,\n        secret: Field,\n        sender: EthAddress,\n        leaf_index: Field,\n    ) {\n        let secret_hash = compute_secret_hash(secret);\n        let message_hash = compute_l1_to_l2_message_hash(\n            sender,\n            self.chain_id(),\n            /*recipient=*/\n            self.this_address(),\n            self.version(),\n            content,\n            secret_hash,\n            leaf_index,\n        );\n        let nullifier = compute_l1_to_l2_message_nullifier(message_hash, secret);\n\n        assert(\n            !self.nullifier_exists(nullifier, self.this_address()),\n            \"L1-to-L2 message is already nullified\",\n        );\n        assert(\n            self.l1_to_l2_msg_exists(message_hash, leaf_index),\n            \"Tried to consume nonexistent L1-to-L2 message\",\n        );\n\n        self.push_nullifier(nullifier);\n    }\n\n    /// Sends an \"L2 -> L1 message\" from this function (Aztec, L2) to a smart\n    /// contract on Ethereum (L1). L1 contracts which are designed to\n    /// send/receive messages to/from Aztec are called \"Portal Contracts\".\n    ///\n    /// Common use cases include withdrawals, cross-chain asset transfers, and\n    /// triggering L1 actions based on L2 state changes.\n    ///\n    /// The message will be inserted into an Aztec \"Outbox\" contract on L1,\n    /// when this transaction's block is proposed to L1.\n    /// Sending the message will not result in any immediate state changes in\n    /// the target portal contract. The message will need to be manually\n    /// consumed from the Outbox through a separate Ethereum transaction: a user\n    /// will need to call a function of the portal contract -- a function\n    /// specifically designed to make a call to the Outbox to consume the\n    /// message.\n    /// The message will only be available for consumption once the _epoch_\n    /// proof has been submitted. Given that there are multiple Aztec blocks\n    /// within an epoch, it might take some time for this epoch proof to be\n    /// submitted -- especially if the block was near the start of an epoch.\n    ///\n    /// # Arguments\n    /// * `recipient` - Ethereum address that will receive the message\n    /// * `content` - Message content (32 bytes as a Field element)\n    ///\n    pub fn message_portal(_self: &mut Self, recipient: EthAddress, content: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { send_l2_to_l1_msg(recipient, content) };\n    }\n\n    /// Calls a public function on another contract.\n    ///\n    /// Will revert if the called function reverts or runs out of gas.\n    ///\n    /// # Arguments\n    /// * `contract_address` - Address of the contract to call\n    /// * `function_selector` - Function to call on the target contract\n    /// * `args` - Arguments to pass to the function\n    /// * `gas_opts` - An optional allocation of gas to the called function.\n    ///\n    /// # Returns\n    /// * `[Field]` - Return data from the called function\n    ///\n    pub unconstrained fn call_public_function(\n        _self: &mut Self,\n        contract_address: AztecAddress,\n        function_selector: FunctionSelector,\n        args: [Field],\n        gas_opts: GasOpts,\n    ) -> [Field] {\n        let calldata = args.push_front(function_selector.to_field());\n\n        call(\n            gas_opts.l2_gas.unwrap_or(MAX_U32_VALUE),\n            gas_opts.da_gas.unwrap_or(MAX_U32_VALUE),\n            contract_address,\n            calldata,\n        );\n        // Use success_copy to determine whether the call succeeded\n        let success = success_copy();\n\n        let result_data = returndata_copy(0, returndata_size());\n        if !success {\n            // Rethrow the revert data.\n            avm_revert(result_data);\n        }\n        result_data\n    }\n\n    /// Makes a read-only call to a public function on another contract.\n    ///\n    /// This is similar to Solidity's `staticcall`. The called function\n    /// cannot modify state or emit events. Any nested calls are constrained to\n    /// also be staticcalls.\n    ///\n    /// Useful for querying data from other contracts safely.\n    ///\n    /// Will revert if the called function reverts or runs out of gas.\n    ///\n    /// # Arguments\n    /// * `contract_address` - Address of the contract to call\n    /// * `function_selector` - Function to call on the target contract\n    /// * `args` - Array of arguments to pass to the called function\n    /// * `gas_opts` - An optional allocation of gas to the called function.\n    ///\n    /// # Returns\n    /// * `[Field]` - Return data from the called function\n    ///\n    pub unconstrained fn static_call_public_function(\n        _self: &mut Self,\n        contract_address: AztecAddress,\n        function_selector: FunctionSelector,\n        args: [Field],\n        gas_opts: GasOpts,\n    ) -> [Field] {\n        let calldata = args.push_front(function_selector.to_field());\n\n        call_static(\n            gas_opts.l2_gas.unwrap_or(MAX_U32_VALUE),\n            gas_opts.da_gas.unwrap_or(MAX_U32_VALUE),\n            contract_address,\n            calldata,\n        );\n        // Use success_copy to determine whether the call succeeded\n        let success = success_copy();\n\n        let result_data = returndata_copy(0, returndata_size());\n        if !success {\n            // Rethrow the revert data.\n            avm_revert(result_data);\n        }\n        result_data\n    }\n\n    /// Adds a new note hash to the Aztec blockchain's global Note Hash Tree.\n    ///\n    /// Notes are ordinarily constructed and emitted by _private_ functions, to\n    /// ensure that both the content of the note, and the contract that emitted\n    /// the note, stay private.\n    ///\n    /// There are however some useful patterns whereby a note needs to contain\n    /// _public_ data. The ability to push a new note_hash from a _public_\n    /// function means that notes can be injected with public data immediately\n    /// -- as soon as the public value is known. The slower alternative would\n    /// be to submit a follow-up transaction so that a private function can\n    /// inject the data. Both are possible on Aztec.\n    ///\n    /// Search \"Partial Note\" for a very common pattern which enables a note\n    /// to be \"partially\" populated with some data in a _private_ function, and\n    /// then later \"completed\" with some data in a public function.\n    ///\n    /// # Arguments\n    /// * `note_hash` - The hash of the note to add to the tree\n    ///\n    /// # Advanced\n    /// * The note hash will be siloed with the contract address by the protocol\n    ///\n    pub fn push_note_hash(_self: &mut Self, note_hash: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_note_hash(note_hash) };\n    }\n\n    /// Adds a new nullifier to the Aztec blockchain's global Nullifier Tree.\n    ///\n    /// Whilst nullifiers are primarily intended as a _privacy-preserving_\n    /// record of a one-time action, they can also be used to efficiently\n    /// record _public_ one-time actions too. Hence why you're seeing this\n    /// function within the PublicContext.\n    /// An example is to check whether a contract has been published: we emit\n    /// a nullifier that is deterministic, but whose preimage is _not_ private.\n    ///\n    /// # Arguments\n    /// * `nullifier` - A unique field element that represents the consumed\n    ///   state\n    ///\n    /// # Advanced\n    /// * Nullifier is immediately added to the global nullifier tree\n    /// * Emitted nullifiers are immediately visible to all\n    ///   subsequent transactions in the same block\n    /// * Automatically siloed with the contract address by the protocol\n    /// * Used for preventing double-spending and ensuring one-time actions\n    ///\n    pub fn push_nullifier(_self: &mut Self, nullifier: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_nullifier(nullifier) };\n    }\n\n    /// Returns the address of the current contract being executed.\n    ///\n    /// This is equivalent to `address(this)` in Solidity (hence the name).\n    /// Use this to identify the current contract's address, commonly needed for\n    /// access control or when interacting with other contracts.\n    ///\n    /// # Returns\n    /// * `AztecAddress` - The contract address of the current function being\n    ///                    executed.\n    ///\n    pub fn this_address(_self: Self) -> AztecAddress {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            address()\n        }\n    }\n\n    /// Returns the contract address that initiated this function call.\n    ///\n    /// This is similar to `msg.sender` in Solidity (hence the name).\n    ///\n    /// Important Note: Since Aztec doesn't have a concept of an EoA (\n    /// Externally-owned Account), the msg_sender is \"undefined\" for the first\n    /// function call of every transaction. A value of `-1` is returned in such\n    /// cases, and is enforced by the protocol's kernel circuits.\n    /// The first function call of a tx is likely to be a call to the user's\n    /// account contract, so this quirk will most often be handled by account\n    /// contract developers.\n    ///\n    /// # Returns\n    /// * `AztecAddress` - The address of the account or contract that called\n    ///   this function\n    ///\n    /// # Examples\n    /// ```rust\n    /// #[aztec(public)]\n    /// fn transfer(context: &mut PublicContext, to: AztecAddress, amount: u64) {\n    ///     let sender = context.msg_sender();\n    ///     // Only the sender can transfer their own tokens\n    ///     assert(sender == get_token_owner(), \"Unauthorized\");\n    /// }\n    /// ```\n    ///\n    /// # Advanced\n    /// * Value is provided by the AVM sender opcode\n    /// * In nested calls, this is the immediate caller, not the original\n    ///   transaction sender\n    /// * Globally visible unlike private execution where it's contract-local\n    pub fn msg_sender(_self: Self) -> AztecAddress {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            sender()\n        }\n    }\n\n    /// Returns the function selector of the currently-executing function.\n    ///\n    /// This is similar to `msg.sig` in Solidity, returning the first 4\n    /// bytes of the function signature.\n    ///\n    /// # Returns\n    /// * `FunctionSelector` - The 4-byte function identifier\n    ///\n    /// # Advanced\n    /// * Extracted from the first element of calldata\n    /// * Used internally for function dispatch in the AVM\n    ///\n    pub fn selector(_self: Self) -> FunctionSelector {\n        // The selector is the first element of the calldata when calling a public function through dispatch.\n        // Safety: AVM opcodes are constrained by the AVM itself\n        let raw_selector: [Field; 1] = unsafe { calldata_copy(0, 1) };\n        FunctionSelector::from_field(raw_selector[0])\n    }\n\n    /// Returns the hash of the arguments passed to the current function.\n    ///\n    /// Very low-level function: The #[public] macro uses this internally.\n    /// Smart contract developers typically won't need to access this\n    /// directly as arguments are automatically made available.\n    ///\n    /// # Returns\n    /// * `Field` - Hash of the function arguments\n    ///\n    pub fn get_args_hash(mut self) -> Field {\n        if !self.args_hash.is_some() {\n            self.args_hash = Option::some((self.compute_args_hash)());\n        }\n\n        self.args_hash.unwrap_unchecked()\n    }\n\n    /// Returns the \"transaction fee\" for the current transaction.\n    /// This is the final tx fee that will be deducted from the fee_payer's\n    /// \"fee-juice\" balance (in the protocol's Base Rollup circuit).\n    ///\n    /// # Returns\n    /// * `Field` - The actual, final cost of the transaction, taking into account:\n    ///             the actual gas used during the setup and app-logic phases,\n    ///             and the fixed amount of gas that's been allocated by the user\n    ///             for the teardown phase.\n    ///             I.e. effectiveL2FeePerGas * l2GasUsed + effectiveDAFeePerGas * daGasUsed\n    ///\n    /// This will return `0` during the \"setup\" and \"app-logic\" phases of\n    /// tx execution (because the final tx fee is not known at that time).\n    /// This will only return a nonzero value during the \"teardown\" phase of\n    /// execution, where the final tx fee can actually be computed.\n    ///\n    /// Regardless of _when_ this function is called during the teardown phase,\n    /// it will always return the same final tx fee value. The teardown phase\n    /// does not consume a variable amount of gas: it always consumes a\n    /// pre-allocated amount of gas, as specified by the user when they generate\n    /// their tx.\n    ///\n    pub fn transaction_fee(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            transaction_fee()\n        }\n    }\n\n    /// Returns the chain ID of the current network.\n    ///\n    /// This is similar to `block.chainid` in Solidity. Returns the unique\n    /// identifier for the blockchain network this transaction is executing on.\n    ///\n    /// Helps prevent cross-chain replay attacks. Useful if implementing\n    /// multi-chain contract logic.\n    ///\n    /// # Returns\n    /// * `Field` - The chain ID as a field element\n    ///\n    pub fn chain_id(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            chain_id()\n        }\n    }\n\n    /// Returns the Aztec protocol version that this transaction is executing\n    /// under. Different versions may have different rules, opcodes, or\n    /// cryptographic primitives.\n    ///\n    /// This is similar to how Ethereum has different EVM versions.\n    ///\n    /// Useful for forward/backward compatibility checks\n    ///\n    /// Not to be confused with contract versions; this is the protocol version.\n    ///\n    /// # Returns\n    /// * `Field` - The protocol version as a field element\n    ///\n    pub fn version(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            version()\n        }\n    }\n    /// Returns the current block number.\n    ///\n    /// This is similar to `block.number` in Solidity.\n    ///\n    /// Note: the current block number is only available within a public function\n    /// (as opposed to a private function).\n    ///\n    /// Note: the time intervals between blocks should not be relied upon as\n    /// being consistent:\n    /// - Timestamps of blocks fall within a range, rather than at exact regular\n    ///   intervals.\n    /// - Slots can be missed.\n    /// - Protocol upgrades can completely change the intervals between blocks\n    ///   (and indeed the current roadmap plans to reduce the time between\n    ///   blocks, eventually).\n    /// Use `context.timestamp()` for more-reliable time-based logic.\n    ///\n    /// # Returns\n    /// * `u32` - The current block number\n    ///\n    pub fn block_number(_self: Self) -> u32 {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            block_number()\n        }\n    }\n\n    /// Returns the timestamp of the current block.\n    ///\n    /// This is similar to `block.timestamp` in Solidity.\n    ///\n    /// All functions of all transactions in a block share the exact same\n    /// timestamp (even though technically each transaction is executed\n    /// one-after-the-other).\n    ///\n    /// Important note: Timestamps of Aztec blocks are not at reliably-fixed\n    /// intervals. The proposer of the block has some flexibility to choose a\n    /// timestamp which is in a valid _range_: Obviously the timestamp of this\n    /// block must be strictly greater than that of the previous block, and must\n    /// must be less than the timestamp of whichever ethereum block the aztec\n    /// block is proposed to. Furthermore, if the timestamp is not deemed close\n    /// enough to the actual current time, the committee of validators will not\n    /// attest to the block.\n    ///\n    /// # Returns\n    /// * `u64` - Unix timestamp in seconds\n    ///\n    pub fn timestamp(_self: Self) -> u64 {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            timestamp()\n        }\n    }\n\n    /// Returns the fee per unit of L2 gas for this transaction (aka the \"L2 gas\n    /// price\"), as chosen by the user.\n    ///\n    /// L2 gas covers the cost of executing public functions and handling\n    /// side-effects within the AVM.\n    ///\n    /// # Returns\n    /// * `u128` - Fee per unit of L2 gas\n    ///\n    /// Wallet developers should be mindful that the choice of gas price (which\n    /// is publicly visible) can leak information about the user, e.g.:\n    /// - which wallet software the user is using;\n    /// - the amount of time which has elapsed from the time the user's wallet\n    ///   chose a gas price (at the going rate), to the time of tx submission.\n    ///   This can give clues about the proving time, and hence the nature of\n    ///   the tx.\n    /// - the urgency of the transaction (which is kind of unavoidable, if the\n    ///   tx is indeed urgent).\n    /// - the wealth of the user.\n    /// - the exact user (if the gas price is explicitly chosen by the user to\n    ///   be some unique number like 0.123456789, or their favourite number).\n    /// Wallet devs might wish to consider fuzzing the choice of gas price.\n    ///\n    pub fn base_fee_per_l2_gas(_self: Self) -> u128 {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            base_fee_per_l2_gas()\n        }\n    }\n\n    /// Returns the fee per unit of DA (Data Availability) gas (aka the \"DA gas\n    /// price\").\n    ///\n    /// DA gas covers the cost of making transaction data available on L1.\n    ///\n    /// See the warning in `fee_pre_l2_gas` for how gas prices can be leaky.\n    ///\n    /// # Returns\n    /// * `u128` - Fee per unit of DA gas\n    ///\n    pub fn base_fee_per_da_gas(_self: Self) -> u128 {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            base_fee_per_da_gas()\n        }\n    }\n\n    /// Returns the remaining L2 gas available for this transaction.\n    ///\n    /// Different AVM opcodes consume different amounts of gas.\n    ///\n    /// # Returns\n    /// * `u32` - Remaining L2 gas units\n    ///\n    pub fn l2_gas_left(_self: Self) -> u32 {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            l2_gas_left()\n        }\n    }\n\n    /// Returns the remaining DA (Data Availability) gas available for this\n    /// transaction.\n    ///\n    /// DA gas is consumed when emitting data that needs to be made available\n    /// on L1, such as public logs or state updates.\n    /// All of the side-effects from the private part of the tx also consume\n    /// DA gas before execution of any public functions even begins.\n    ///\n    /// # Returns\n    /// * `u32` - Remaining DA gas units\n    ///\n    pub fn da_gas_left(_self: Self) -> u32 {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            da_gas_left()\n        }\n    }\n\n    /// Checks if the current execution is within a staticcall context, where\n    /// no state changes or logs are allowed to be emitted (by this function\n    /// or any nested function calls).\n    ///\n    /// # Returns\n    /// * `bool` - True if in staticcall context, false otherwise\n    ///\n    pub fn is_static_call(_self: Self) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { is_static_call() } == 1\n    }\n\n    /// Reads raw field values from public storage.\n    /// Reads N consecutive storage slots starting from the given slot.\n    ///\n    /// Very low-level function. Users should typically use the public state\n    /// variable abstractions to perform reads: PublicMutable & PublicImmutable.\n    ///\n    /// # Arguments\n    /// * `storage_slot` - The starting storage slot to read from\n    ///\n    /// # Returns\n    /// * `[Field; N]` - Array of N field values from consecutive storage slots\n    ///\n    /// # Generic Parameters\n    /// * `N` - the number of consecutive slots to return, starting from the\n    ///         `storage_slot`.\n    ///\n    pub fn raw_storage_read<let N: u32>(_self: Self, storage_slot: Field) -> [Field; N] {\n        let mut out = [0; N];\n        for i in 0..N {\n            // Safety: AVM opcodes are constrained by the AVM itself\n            out[i] = unsafe { storage_read(storage_slot + i as Field) };\n        }\n        out\n    }\n\n    /// Reads a typed value from public storage.\n    ///\n    /// Low-level function. Users should typically use the public state\n    /// variable abstractions to perform reads: PublicMutable & PublicImmutable.\n    ///\n    /// # Arguments\n    /// * `storage_slot` - The storage slot to read from\n    ///\n    /// # Returns\n    /// * `T` - The deserialized value from storage\n    ///\n    /// # Generic Parameters\n    /// * `T` - The type that the caller expects to read from the `storage_slot`.\n    ///\n    pub fn storage_read<T>(self, storage_slot: Field) -> T\n    where\n        T: Packable,\n    {\n        T::unpack(self.raw_storage_read(storage_slot))\n    }\n\n    /// Writes raw field values to public storage.\n    /// Writes to N consecutive storage slots starting from the given slot.\n    ///\n    /// Very low-level function. Users should typically use the public state\n    /// variable abstractions to perform writes: PublicMutable & PublicImmutable.\n    ///\n    /// Public storage writes take effect immediately.\n    ///\n    /// # Arguments\n    /// * `storage_slot` - The starting storage slot to write to\n    /// * `values` - Array of N Fields to write to storage\n    ///\n    pub fn raw_storage_write<let N: u32>(_self: Self, storage_slot: Field, values: [Field; N]) {\n        for i in 0..N {\n            // Safety: AVM opcodes are constrained by the AVM itself\n            unsafe { storage_write(storage_slot + i as Field, values[i]) };\n        }\n    }\n\n    /// Writes a typed value to public storage.\n    ///\n    /// Low-level function. Users should typically use the public state\n    /// variable abstractions to perform writes: PublicMutable & PublicImmutable.\n    ///\n    /// # Arguments\n    /// * `storage_slot` - The storage slot to write to\n    /// * `value` - The typed value to write to storage\n    ///\n    /// # Generic Parameters\n    /// * `T` - The type to write to storage.\n    ///\n    pub fn storage_write<T>(self, storage_slot: Field, value: T)\n    where\n        T: Packable,\n    {\n        self.raw_storage_write(storage_slot, value.pack());\n    }\n}\n\n// TODO: consider putting this oracle code in its own file.\n// Unconstrained opcode wrappers (do not use directly).\nunconstrained fn address() -> AztecAddress {\n    address_opcode()\n}\nunconstrained fn sender() -> AztecAddress {\n    sender_opcode()\n}\nunconstrained fn transaction_fee() -> Field {\n    transaction_fee_opcode()\n}\nunconstrained fn chain_id() -> Field {\n    chain_id_opcode()\n}\nunconstrained fn version() -> Field {\n    version_opcode()\n}\nunconstrained fn block_number() -> u32 {\n    block_number_opcode()\n}\nunconstrained fn timestamp() -> u64 {\n    timestamp_opcode()\n}\nunconstrained fn base_fee_per_l2_gas() -> u128 {\n    base_fee_per_l2_gas_opcode()\n}\nunconstrained fn base_fee_per_da_gas() -> u128 {\n    base_fee_per_da_gas_opcode()\n}\nunconstrained fn l2_gas_left() -> u32 {\n    l2_gas_left_opcode()\n}\nunconstrained fn da_gas_left() -> u32 {\n    da_gas_left_opcode()\n}\nunconstrained fn is_static_call() -> u1 {\n    is_static_call_opcode()\n}\nunconstrained fn note_hash_exists(note_hash: Field, leaf_index: u64) -> u1 {\n    note_hash_exists_opcode(note_hash, leaf_index)\n}\nunconstrained fn emit_note_hash(note_hash: Field) {\n    emit_note_hash_opcode(note_hash)\n}\nunconstrained fn nullifier_exists(nullifier: Field, address: Field) -> u1 {\n    nullifier_exists_opcode(nullifier, address)\n}\nunconstrained fn emit_nullifier(nullifier: Field) {\n    emit_nullifier_opcode(nullifier)\n}\nunconstrained fn emit_public_log(message: [Field]) {\n    emit_public_log_opcode(message)\n}\nunconstrained fn l1_to_l2_msg_exists(msg_hash: Field, msg_leaf_index: u64) -> u1 {\n    l1_to_l2_msg_exists_opcode(msg_hash, msg_leaf_index)\n}\nunconstrained fn send_l2_to_l1_msg(recipient: EthAddress, content: Field) {\n    send_l2_to_l1_msg_opcode(recipient, content)\n}\n\nunconstrained fn call(\n    l2_gas_allocation: u32,\n    da_gas_allocation: u32,\n    address: AztecAddress,\n    args: [Field],\n) {\n    call_opcode(l2_gas_allocation, da_gas_allocation, address, args)\n}\n\nunconstrained fn call_static(\n    l2_gas_allocation: u32,\n    da_gas_allocation: u32,\n    address: AztecAddress,\n    args: [Field],\n) {\n    call_static_opcode(l2_gas_allocation, da_gas_allocation, address, args)\n}\n\npub unconstrained fn calldata_copy<let N: u32>(cdoffset: u32, copy_size: u32) -> [Field; N] {\n    calldata_copy_opcode(cdoffset, copy_size)\n}\n\n// `success_copy` is placed immediately after the CALL opcode to get the success value\nunconstrained fn success_copy() -> bool {\n    success_copy_opcode()\n}\n\nunconstrained fn returndata_size() -> u32 {\n    returndata_size_opcode()\n}\n\nunconstrained fn returndata_copy(rdoffset: u32, copy_size: u32) -> [Field] {\n    returndata_copy_opcode(rdoffset, copy_size)\n}\n\npub unconstrained fn avm_return(returndata: [Field]) {\n    return_opcode(returndata)\n}\n\n// This opcode reverts using the exact data given. In general it should only be used\n// to do rethrows, where the revert data is the same as the original revert data.\n// For normal reverts, use Noir's `assert` which, on top of reverting, will also add\n// an error selector to the revert data.\nunconstrained fn avm_revert(revertdata: [Field]) {\n    revert_opcode(revertdata)\n}\n\nunconstrained fn storage_read(storage_slot: Field) -> Field {\n    storage_read_opcode(storage_slot)\n}\n\nunconstrained fn storage_write(storage_slot: Field, value: Field) {\n    storage_write_opcode(storage_slot, value);\n}\n\nimpl Empty for PublicContext {\n    fn empty() -> Self {\n        PublicContext::new(|| 0)\n    }\n}\n\n// TODO: consider putting this oracle code in its own file.\n// AVM oracles (opcodes) follow, do not use directly.\n#[oracle(avmOpcodeAddress)]\nunconstrained fn address_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodeSender)]\nunconstrained fn sender_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodeTransactionFee)]\nunconstrained fn transaction_fee_opcode() -> Field {}\n\n#[oracle(avmOpcodeChainId)]\nunconstrained fn chain_id_opcode() -> Field {}\n\n#[oracle(avmOpcodeVersion)]\nunconstrained fn version_opcode() -> Field {}\n\n#[oracle(avmOpcodeBlockNumber)]\nunconstrained fn block_number_opcode() -> u32 {}\n\n#[oracle(avmOpcodeTimestamp)]\nunconstrained fn timestamp_opcode() -> u64 {}\n\n#[oracle(avmOpcodeBaseFeePerL2Gas)]\nunconstrained fn base_fee_per_l2_gas_opcode() -> u128 {}\n\n#[oracle(avmOpcodeBaseFeePerDaGas)]\nunconstrained fn base_fee_per_da_gas_opcode() -> u128 {}\n\n#[oracle(avmOpcodeL2GasLeft)]\nunconstrained fn l2_gas_left_opcode() -> u32 {}\n\n#[oracle(avmOpcodeDaGasLeft)]\nunconstrained fn da_gas_left_opcode() -> u32 {}\n\n#[oracle(avmOpcodeIsStaticCall)]\nunconstrained fn is_static_call_opcode() -> u1 {}\n\n#[oracle(avmOpcodeNoteHashExists)]\nunconstrained fn note_hash_exists_opcode(note_hash: Field, leaf_index: u64) -> u1 {}\n\n#[oracle(avmOpcodeEmitNoteHash)]\nunconstrained fn emit_note_hash_opcode(note_hash: Field) {}\n\n#[oracle(avmOpcodeNullifierExists)]\nunconstrained fn nullifier_exists_opcode(nullifier: Field, address: Field) -> u1 {}\n\n#[oracle(avmOpcodeEmitNullifier)]\nunconstrained fn emit_nullifier_opcode(nullifier: Field) {}\n\n// TODO(#11124): rename unencrypted to public in avm\n#[oracle(avmOpcodeEmitUnencryptedLog)]\nunconstrained fn emit_public_log_opcode(message: [Field]) {}\n\n#[oracle(avmOpcodeL1ToL2MsgExists)]\nunconstrained fn l1_to_l2_msg_exists_opcode(msg_hash: Field, msg_leaf_index: u64) -> u1 {}\n\n#[oracle(avmOpcodeSendL2ToL1Msg)]\nunconstrained fn send_l2_to_l1_msg_opcode(recipient: EthAddress, content: Field) {}\n\n#[oracle(avmOpcodeCalldataCopy)]\nunconstrained fn calldata_copy_opcode<let N: u32>(cdoffset: u32, copy_size: u32) -> [Field; N] {}\n\n#[oracle(avmOpcodeReturndataSize)]\nunconstrained fn returndata_size_opcode() -> u32 {}\n\n#[oracle(avmOpcodeReturndataCopy)]\nunconstrained fn returndata_copy_opcode(rdoffset: u32, copy_size: u32) -> [Field] {}\n\n#[oracle(avmOpcodeReturn)]\nunconstrained fn return_opcode(returndata: [Field]) {}\n\n// This opcode reverts using the exact data given. In general it should only be used\n// to do rethrows, where the revert data is the same as the original revert data.\n// For normal reverts, use Noir's `assert` which, on top of reverting, will also add\n// an error selector to the revert data.\n#[oracle(avmOpcodeRevert)]\nunconstrained fn revert_opcode(revertdata: [Field]) {}\n\n#[oracle(avmOpcodeCall)]\nunconstrained fn call_opcode(\n    l2_gas_allocation: u32,\n    da_gas_allocation: u32,\n    address: AztecAddress,\n    args: [Field],\n) {}\n\n#[oracle(avmOpcodeStaticCall)]\nunconstrained fn call_static_opcode(\n    l2_gas_allocation: u32,\n    da_gas_allocation: u32,\n    address: AztecAddress,\n    args: [Field],\n) {}\n\n#[oracle(avmOpcodeSuccessCopy)]\nunconstrained fn success_copy_opcode() -> bool {}\n\n#[oracle(avmOpcodeStorageRead)]\nunconstrained fn storage_read_opcode(storage_slot: Field) -> Field {}\n\n#[oracle(avmOpcodeStorageWrite)]\nunconstrained fn storage_write_opcode(storage_slot: Field, value: Field) {}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/aztec-nr/aztec/src/context/public_context.nr"},"75":{"source":"use dep::protocol_types::{\n    address::{AztecAddress, EthAddress},\n    constants::{\n        GENERATOR_INDEX__FUNCTION_ARGS, GENERATOR_INDEX__MESSAGE_NULLIFIER,\n        GENERATOR_INDEX__PUBLIC_BYTECODE, GENERATOR_INDEX__PUBLIC_CALLDATA,\n        GENERATOR_INDEX__SECRET_HASH, MAX_PACKED_PUBLIC_BYTECODE_SIZE_IN_FIELDS,\n    },\n    hash::{\n        poseidon2_hash_subarray, poseidon2_hash_with_separator, poseidon2_hash_with_separator_slice,\n        sha256_to_field,\n    },\n    point::Point,\n    traits::{Hash, ToField},\n};\n\npub use dep::protocol_types::hash::{compute_siloed_nullifier, pedersen_hash};\n\npub fn pedersen_commitment<let N: u32>(inputs: [Field; N], hash_index: u32) -> Point {\n    std::hash::pedersen_commitment_with_separator(inputs, hash_index)\n}\n\npub fn compute_secret_hash(secret: Field) -> Field {\n    poseidon2_hash_with_separator([secret], GENERATOR_INDEX__SECRET_HASH)\n}\n\npub fn compute_l1_to_l2_message_hash(\n    sender: EthAddress,\n    chain_id: Field,\n    recipient: AztecAddress,\n    version: Field,\n    content: Field,\n    secret_hash: Field,\n    leaf_index: Field,\n) -> Field {\n    let mut hash_bytes = [0 as u8; 224];\n    let sender_bytes: [u8; 32] = sender.to_field().to_be_bytes();\n    let chain_id_bytes: [u8; 32] = chain_id.to_be_bytes();\n    let recipient_bytes: [u8; 32] = recipient.to_field().to_be_bytes();\n    let version_bytes: [u8; 32] = version.to_be_bytes();\n    let content_bytes: [u8; 32] = content.to_be_bytes();\n    let secret_hash_bytes: [u8; 32] = secret_hash.to_be_bytes();\n    let leaf_index_bytes: [u8; 32] = leaf_index.to_be_bytes();\n\n    for i in 0..32 {\n        hash_bytes[i] = sender_bytes[i];\n        hash_bytes[i + 32] = chain_id_bytes[i];\n        hash_bytes[i + 64] = recipient_bytes[i];\n        hash_bytes[i + 96] = version_bytes[i];\n        hash_bytes[i + 128] = content_bytes[i];\n        hash_bytes[i + 160] = secret_hash_bytes[i];\n        hash_bytes[i + 192] = leaf_index_bytes[i];\n    }\n\n    sha256_to_field(hash_bytes)\n}\n\n// The nullifier of a l1 to l2 message is the hash of the message salted with the secret\npub fn compute_l1_to_l2_message_nullifier(message_hash: Field, secret: Field) -> Field {\n    poseidon2_hash_with_separator([message_hash, secret], GENERATOR_INDEX__MESSAGE_NULLIFIER)\n}\n\npub struct ArgsHasher {\n    pub fields: [Field],\n}\n\nimpl Hash for ArgsHasher {\n    fn hash(self) -> Field {\n        hash_args(self.fields)\n    }\n}\n\nimpl ArgsHasher {\n    pub fn new() -> Self {\n        Self { fields: [] }\n    }\n\n    pub fn add(&mut self, field: Field) {\n        self.fields = self.fields.push_back(field);\n    }\n\n    pub fn add_multiple<let N: u32>(&mut self, fields: [Field; N]) {\n        for i in 0..N {\n            self.fields = self.fields.push_back(fields[i]);\n        }\n    }\n}\n\n// Computes the hash of input arguments or return values for private functions, or for authwit creation.\npub fn hash_args_array<let N: u32>(args: [Field; N]) -> Field {\n    if args.len() == 0 {\n        0\n    } else {\n        poseidon2_hash_with_separator(args, GENERATOR_INDEX__FUNCTION_ARGS)\n    }\n}\n\n// Same as `hash_args_array`, but takes a slice instead of an array.\npub fn hash_args(args: [Field]) -> Field {\n    if args.len() == 0 {\n        0\n    } else {\n        poseidon2_hash_with_separator_slice(args, GENERATOR_INDEX__FUNCTION_ARGS)\n    }\n}\n\n// Computes the hash of calldata for public functions.\npub fn hash_calldata_array<let N: u32>(calldata: [Field; N]) -> Field {\n    if calldata.len() == 0 {\n        0\n    } else {\n        poseidon2_hash_with_separator(calldata, GENERATOR_INDEX__PUBLIC_CALLDATA)\n    }\n}\n\n// Same as `hash_calldata_array`, but takes a slice instead of an array.\npub fn hash_calldata(calldata: [Field]) -> Field {\n    if calldata.len() == 0 {\n        0\n    } else {\n        poseidon2_hash_with_separator_slice(calldata, GENERATOR_INDEX__PUBLIC_CALLDATA)\n    }\n}\n\n/**\n * Computes the public bytecode commitment for a contract class.\n * The commitment is `hash([separator, ...bytecode])` where bytecode omits the length prefix present\n * in `packed_bytecode`.\n *\n * @param packed_bytecode - The packed bytecode of the contract class. 0th word is the length in bytes.\n *    packed_bytecode is mutable so that we can avoid copying the array to construct one starting with\n *    separator instead of length.\n * @returns The public bytecode commitment.\n */\npub fn compute_public_bytecode_commitment(\n    mut packed_public_bytecode: [Field; MAX_PACKED_PUBLIC_BYTECODE_SIZE_IN_FIELDS],\n) -> Field {\n    // First field element contains the length of the bytecode\n    let bytecode_length_in_bytes: u32 = packed_public_bytecode[0] as u32;\n    let bytecode_length_in_fields: u32 =\n        (bytecode_length_in_bytes / 31) + (bytecode_length_in_bytes % 31 != 0) as u32;\n    // Don't allow empty public bytecode.\n    // AVM doesn't handle execution of contracts that exist with empty bytecode.\n    assert(bytecode_length_in_fields != 0);\n    assert(bytecode_length_in_fields < MAX_PACKED_PUBLIC_BYTECODE_SIZE_IN_FIELDS);\n\n    // Packed_bytecode's 0th entry is the length. Replace it with separator before hashing.\n    let separator = GENERATOR_INDEX__PUBLIC_BYTECODE.to_field();\n    packed_public_bytecode[0] = separator;\n    // +1 to length to account for the separator\n    let nonzero_length = bytecode_length_in_fields + 1;\n\n    poseidon2_hash_subarray(packed_public_bytecode, nonzero_length)\n    // NOTE: we use poseidon2_hash_subarray here because we want to hash the bytecode only up to\n    // its nonzero length. We do NOT want to include a `1` at the end to indicate \"variable length\",\n    // and we want to enforce that all trailing elements are zero.\n}\n\n#[test]\nunconstrained fn compute_var_args_hash() {\n    let mut input = ArgsHasher::new();\n    for i in 0..100 {\n        input.add(i as Field);\n    }\n    let hash = input.hash();\n    dep::std::println(hash);\n    assert(hash == 0x19b0d74feb06ebde19edd85a28986c97063e84b3b351a8b666c7cac963ce655f);\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/aztec-nr/aztec/src/hash.nr"},"108":{"source":"use poseidon::poseidon2::Poseidon2Hasher;\nuse std::{collections::umap::UHashMap, hash::BuildHasherDefault};\n\nuse super::utils::AsStrQuote;\nuse super::utils::get_storage_size;\n\n/// Stores a map from a module to the name of the struct that describes its storage layout.\n/// This is then used when generating a `storage_layout()` getter on the contract struct.\npub comptime mut global STORAGE_LAYOUT_NAME: UHashMap<Module, Quoted, BuildHasherDefault<Poseidon2Hasher>> =\n    UHashMap::default();\n\n/// Marks a struct as the one describing the storage layout of a contract.\n///\n/// The contract's storage is accessed via the `storage` variable, which will will automatically be made available in\n/// all functions as an instance of the struct this macro was applied to.\n///\n/// Only a single struct in the entire contract should have this macro (or `storage_no_init`) applied to it, and the\n/// struct has to be called 'Storage'.\npub comptime fn storage(s: TypeDefinition) -> Quoted {\n    let struct_name = s.name();\n    if struct_name != quote { Storage } {\n        panic(\n            f\"The #[storage] macro can only be applied to a struct with name 'Storage', got '{struct_name}' instead.\",\n        )\n    }\n\n    assert(\n        !s.has_named_attribute(\"storage_no_init\"),\n        f\"Only one of #[storage] and #[storage_no_init] can be applied to the Storage struct.\",\n    );\n\n    // This macro performs three things:\n    //  - it marks the contract as having storage, so that `macros::utils::module_has_storage` will return true and\n    //    functions will have the storage variable injected and initialized via the `init` function.\n    //  - it implements said `init` function by allocating appropriate storage slots to each state variable.\n    //  - it exposes the storage layout by creating a `StorageLayout` struct that is exposed via the `abi(storage)`\n    //    macro.\n    let mut slot: u32 = 1;\n    let mut storage_vars_constructors = &[];\n    let mut storage_layout_fields = &[];\n    let mut storage_layout_constructors = &[];\n\n    // TODO(#8658): uncomment the code below to inject the Context type parameter.\n    //let mut new_storage_fields = &[];\n    //let context_generic = s.add_generic(\"Context\");\n    for field in s.fields_as_written() {\n        // FIXME: This doesn't handle field types with generics\n        let (name, typ, _) = field;\n        let (storage_field_constructor, storage_size) =\n            generate_storage_field_constructor(typ, quote { $slot });\n        storage_vars_constructors =\n            storage_vars_constructors.push_back(quote { $name: $storage_field_constructor });\n        // We have `Storable` in a separate `.nr` file instead of defining it in the last quote of this function\n        // because that way a dev gets a more reasonable error if he defines a struct with the same name in\n        // a contract.\n        storage_layout_fields = storage_layout_fields.push_back(\n            quote { pub $name: dep::aztec::state_vars::storage::Storable },\n        );\n        storage_layout_constructors = storage_layout_constructors.push_back(\n            quote { $name: dep::aztec::state_vars::storage::Storable { slot: $slot } },\n        );\n        //let with_context_generic = add_context_generic(typ, context_generic);\n        //println(with_context_generic);\n        //new_storage_fields = new_storage_fields.push_back((name,  with_context_generic ));\n        slot += storage_size;\n    }\n\n    //s.set_fields(new_storage_fields);\n    let storage_vars_constructors = storage_vars_constructors.join(quote {,});\n    let storage_impl = quote {\n        impl<Context> Storage<Context> {\n            fn init(context: Context) -> Self {\n                Self {\n                    $storage_vars_constructors\n                }\n            }\n        }\n    };\n\n    let storage_layout_fields = storage_layout_fields.join(quote {,});\n    let storage_layout_constructors = storage_layout_constructors.join(quote {,});\n\n    let module = s.module();\n    let module_name = module.name();\n    let storage_layout_name = f\"STORAGE_LAYOUT_{module_name}\".quoted_contents();\n    let (module_name_str, module_name_len) = module_name.as_str_quote();\n    STORAGE_LAYOUT_NAME.insert(module, storage_layout_name);\n\n    quote {\n        $storage_impl\n\n        pub struct StorageLayoutFields {\n            $storage_layout_fields\n        }\n\n        pub struct StorageLayout<let N: u32> {\n            pub contract_name: str<N>,\n            pub fields: StorageLayoutFields\n        }\n\n        #[abi(storage)]\n        pub global $storage_layout_name: StorageLayout<$module_name_len> = StorageLayout {\n            contract_name: $module_name_str,\n            fields: StorageLayoutFields { $storage_layout_constructors }\n        };\n    }\n}\n\n/// Same as `storage`, except the user is in charge of providing an implementation of the `init` constructor function\n/// with signature `fn init<Context>(context: Context) -> Self`, which allows for manual control of storage slot\n/// allocation. Similarly, no `StorageLayout` struct will be created.\n///\n/// The contract's storage is accessed via the `storage` variable, which will will automatically be made available in\n/// all functions as an instance of the struct this macro was applied to.\n///\n/// Only a single struct in the entire contract can have this macro (or storage_no_init) applied to it, and the struct\n/// has to be called 'Storage'.\npub comptime fn storage_no_init(s: TypeDefinition) {\n    // All `storage` does is provide the `init` implementation, so we don't need to do anything here. Applying this\n    // macro however will cause for `macros::utils::module_has_storage` to return true, resulting in the injection of\n    // the `storage` variable.\n\n    // We do need to make sure that the type is called Storage, since we'll do `Storage::init` later on.\n\n    if s.name() != quote { Storage } {\n        let name = s.name();\n        panic(\n            f\"The #[storage_no_init] macro can only be applied to a struct with name 'Storage', got '{name}' instead.\",\n        )\n    }\n\n    assert(\n        !s.has_named_attribute(\"storage\"),\n        f\"Only one of #[storage] and #[storage_no_init] can be applied to the Storage struct.\",\n    );\n}\n\n/// Returns the expression required to initialize a state variable with a given slot, along with its serialization size,\n/// i.e. how many contiguous storage slots the variable requires.\ncomptime fn generate_storage_field_constructor(typ: Type, slot: Quoted) -> (Quoted, u32) {\n    assert(\n        typ.as_data_type().is_some(),\n        \"Storage containers must be generic structs of the form `Container<_, Context>`, or Map<Key, _, Context>\",\n    );\n    let (container_struct, generics) = typ.as_data_type().unwrap();\n    let struct_name = container_struct.name();\n\n    let constructor = if is_storage_map(typ) {\n        // Map state variables recursively initialize their contents - this includes nested maps.\n        let (value_constructor, _) =\n            generate_storage_field_constructor(generics[1], quote { slot });\n\n        quote { $struct_name::new(context, $slot, | context, slot | { $value_constructor }) }\n    } else {\n        // We assume below that all state variables implement `fn new<Context>(context: Context, slot: Field) -> Self`.\n        quote { $struct_name::new(context, $slot)}\n    };\n\n    (constructor, get_storage_size(typ))\n}\n\n/// Returns true if `typ` is `state_vars::map::Map`.\ncomptime fn is_storage_map(typ: Type) -> bool {\n    if typ.as_data_type().is_some() {\n        let (def, generics) = typ.as_data_type().unwrap();\n        let maybe_map = if (def.name() == quote { Map }) & (generics.len() == 3) {\n            let maybe_key = generics[0];\n            let maybe_value = generics[1];\n            let maybe_context = generics[2];\n            quote { crate::state_vars::map::Map<$maybe_key, $maybe_value, $maybe_context> }.as_type()\n        } else {\n            quote {()}.as_type()\n        };\n        typ == maybe_map\n    } else {\n        false\n    }\n}\n\ncomptime fn add_context_generic(typ: Type, context_generic: Type) -> Type {\n    let (def, mut generics) = typ.as_data_type().expect(\n        f\"Storage containers must be generic structs of the form `Container<..., Context>`\",\n    );\n    let name = def.name();\n\n    if is_storage_map(typ) {\n        generics[generics.len() - 2] = add_context_generic(generics[1], context_generic);\n        generics[generics.len() - 1] = context_generic;\n    } else {\n        generics[generics.len() - 1] = context_generic;\n    }\n\n    let generics = generics.map(|typ: Type| quote {$typ}).join(quote {,});\n    quote { $name<$generics> }.as_type()\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/aztec-nr/aztec/src/macros/storage.nr"},"177":{"source":"use crate::state_vars::storage::HasStorageSlot;\nuse dep::protocol_types::{storage::map::derive_storage_slot_in_map, traits::ToField};\n\n/// Map\n///\n/// A key-value storage container that maps keys to state variables, similar\n/// to Solidity mappings.\n///\n/// `Map` enables you to associate keys (like addresses or other identifiers)\n/// with state variables in your Aztec smart contract. This is conceptually\n/// similar to Solidity's `mapping(K => V)` syntax, where you can store and\n/// retrieve values by their associated keys.\n///\n/// You can declare a state variable contained within a Map in your contract's\n/// #[storage] struct.\n///\n/// For example, you might use\n/// `Map<AztecAddress, PrivateMutable<ValueNote, Context>, Context>` to track\n/// token balances for different users, similar to how you'd use\n/// `mapping(address => uint256)` in Solidity.\n///\n/// > Aside: the verbose `Context` in the declaration is a consequence of\n/// > leveraging Noir's regular syntax for generics to ensure that certain\n/// > state variable methods can only be called in some contexts (private,\n/// > public, utility).\n///\n/// The methods of Map are:\n/// - `at` (access state variable for a given key)\n/// (see the method's own doc comments for more info).\n///\n/// ## Generic Parameters\n/// - `K`: The key type (must implement `ToField` trait for hashing)\n/// - `V`: The value type:\n///   - any Aztec state variable:\n///     - `PublicMutable`\n///     - `PublicImmutable`\n///     - `PrivateMutable`\n///     - `PrivateImmutable`\n///     - `PrivateSet`\n///     - `DelayedPublicMutable`\n///     - `Map`\n/// - `Context`: The execution context (handles private/public function\n///   contexts)\n///\n/// ## Usage\n/// Maps are typically declared in your contract's #[storage] struct and\n/// accessed\n/// using the `at(key)` method to get the state variable for a specific key.\n/// The resulting state variable can then be read from or written to using its\n/// own methods.\n///\n/// ## Advanced\n/// Internally, `Map` uses a single base storage slot to represent the\n/// mapping\n/// itself, similar to Solidity's approach. Individual key-value pairs are\n/// stored at derived storage slots computed by hashing the base storage\n/// slot\n/// with the key using Poseidon2. This ensures:\n/// - No storage slot collisions between different keys\n/// - Uniform distribution of storage slots across the storage space\n/// - Compatibility with Aztec's storage tree structure\n/// - Gas-efficient storage access patterns similar to Solidity mappings\n///\n/// The storage slot derivation uses `derive_storage_slot_in_map(base_slot,\n/// key)` which computes `poseidon2_hash([base_slot, key.to_field()])`,\n/// ensuring cryptographically secure slot separation.\n///\n/// docs:start:map\npub struct Map<K, V, Context> {\n    context: Context,\n    storage_slot: Field,\n    state_var_constructor: fn(Context, Field) -> V,\n}\n// docs:end:map\n\n// Map reserves a single storage slot regardless of what it stores because\n// nothing is stored at said slot: it is only used to derive the storage slots\n// of nested state variables, which is expected to never result in collisions\n// or slots being close to one another due to these being hashes. This mirrors\n// the strategy adopted by Solidity mappings.\nimpl<K, T, Context> HasStorageSlot<1> for Map<K, T, Context> {\n    fn get_storage_slot(self) -> Field {\n        self.storage_slot\n    }\n}\n\nimpl<K, V, Context> Map<K, V, Context> {\n    /// Initializes a new Map state variable.\n    ///\n    /// This function is usually automatically called within the #[storage]\n    /// macro.\n    /// You typically don't need to call this directly when writing smart contracts.\n    ///\n    /// # Arguments\n    ///\n    /// * `context` - One of `PrivateContext`/`PublicContext`/`UtilityContext`.\n    ///               The Context determines which methods of this struct will\n    ///               be made available to the calling smart contract function.\n    /// * `storage_slot` - A unique identifier for this Map within the contract.\n    ///                    Usually, the #[storage] macro will determine an\n    ///                    appropriate storage_slot automatically. A smart\n    ///                    contract dev shouldn't have to worry about this, as\n    ///                    it's managed behind the scenes.\n    /// * `state_var_constructor` - A function that creates the value type (V)\n    ///                             given a context and storage slot. This is\n    ///                             typically the constructor of the state\n    ///                             variable type being stored in the Map.\n    ///\n    // docs:start:new\n    pub fn new(\n        context: Context,\n        storage_slot: Field,\n        state_var_constructor: fn(Context, Field) -> V,\n    ) -> Self {\n        assert(storage_slot != 0, \"Storage slot 0 not allowed. Storage slots must start from 1.\");\n        Map { context, storage_slot, state_var_constructor }\n    }\n    // docs:end:new\n\n    /// Returns the state variable associated with the given key.\n    ///\n    /// This is equivalent to accessing `mapping[key]` in Solidity. It returns\n    /// the state variable instance for the specified key, which can then be\n    /// used to read or write the value at that key.\n    ///\n    /// Unlike Solidity mappings which return the value directly, this returns\n    /// the state variable wrapper (like PrivateMutable, PublicMutable, etc.)\n    /// that you then call methods on to interact with the actual value.\n    ///\n    /// # Arguments\n    ///\n    /// * `key` - The key to look up in the map. Must implement the ToField\n    ///           trait (which most basic Noir & Aztec types do).\n    ///\n    /// # Returns\n    ///\n    /// * `V` - The state variable instance for this key. You can then call\n    ///         methods like `.read()`, `.write()`, `.get_note()`, etc. on this\n    ///         depending on the specific state variable type.\n    ///\n    /// # Example\n    ///\n    /// ```noir\n    /// // Get a user's balance (assuming PrivateMutable<ValueNote>)\n    /// let user_balance = storage.balances.at(user_address);\n    /// let current_note = user_balance.get_note();\n    ///\n    /// // Update the balance\n    /// user_balance.replace(new_note);\n    /// ```\n    ///\n    // docs:start:at\n    pub fn at(self, key: K) -> V\n    where\n        K: ToField,\n    {\n        // TODO(#1204): use a generator index for the storage slot\n        let derived_storage_slot = derive_storage_slot_in_map(self.storage_slot, key);\n\n        let state_var_constructor = self.state_var_constructor;\n        state_var_constructor(self.context, derived_storage_slot)\n    }\n    // docs:end:at\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/aztec-nr/aztec/src/state_vars/map.nr"},"185":{"source":"use crate::{\n    context::{PrivateContext, PublicContext, UtilityContext},\n    state_vars::storage::HasStorageSlot,\n    utils::with_hash::WithHash,\n};\nuse protocol_types::{\n    constants::GENERATOR_INDEX__INITIALIZATION_NULLIFIER, hash::poseidon2_hash_with_separator,\n    traits::Packable,\n};\n\n/// # PublicImmutable\n///\n/// PublicImmutable is a public state variable type for values that are set once\n/// during initialization and remain permanently unchanged.\n///\n/// You can declare a state variable of type PublicImmutable within your contract's\n/// #[storage] struct:\n///\n/// E.g.:\n/// `your_variable: PublicImmutable<T, Context>`\n///\n/// PublicImmutable stores an immutable value in public state which can be _read_\n/// from public, utility and even _private_ execution contexts.\n///\n/// The methods of PublicImmutable are:\n/// - `initialize`\n/// - `read`\n/// (see the methods' own doc comments for more info).\n///\n/// # Generic Parameters:\n///\n/// * `T` - The type of value stored (must implement Packable).\n/// * `Context` - The execution context (PublicContext, PrivateContext, or UtilityContext).\n///\n/// # Advanced\n///\n/// PublicImmutable leverages `WithHash<T>` to enable efficient private reads of\n/// public storage. The `WithHash` wrapper optimizes reads by hashing values that would\n/// be larger than a single field into a single field, then proving inclusion of only\n/// the hash in public storage.\n///\n/// This optimization is particularly valuable when T packs to multiple fields,\n/// as it maintains \"almost constant\" verification overhead regardless of the\n/// original data size.\n///\n/// ## Optimizing private reads in your contract\n/// Since reading T from public immutable storage in private contexts has \"almost\n/// constant\" constraint costs regardless of T's size, it's recommended to group\n/// multiple values into a single struct when they are to be read together. This is\n/// typically useful for configuration data set during contract initialization. E.g.:\n///\n/// ```noir\n/// use dep::aztec::protocol_types::{address::AztecAddress, traits::Packable};\n/// use std::meta::derive;\n///\n/// #[derive(Eq, Packable)]\n/// pub struct Config \\{\n///     pub address_1: AztecAddress,\n///     pub value_1: u128,\n///     pub value_2: u64,\n///     ...\n/// }\n/// ```\n///\n// docs:start:public_immutable_struct\npub struct PublicImmutable<T, Context> {\n    context: Context,\n    storage_slot: Field,\n}\n// docs:end:public_immutable_struct\n\n/// `WithHash<T>` stores both the packed value (using O fields) and its hash (1 field), requiring O = M + 1 total\n/// fields.\nimpl<T, Context, let M: u32, let O: u32> HasStorageSlot<O> for PublicImmutable<T, Context>\nwhere\n    WithHash<T, M>: Packable<N = O>,\n{\n    fn get_storage_slot(self) -> Field {\n        self.storage_slot\n    }\n}\n\nimpl<T, Context> PublicImmutable<T, Context> {\n    /// Initializes a new PublicImmutable state variable.\n    ///\n    /// This function is usually automatically called within the #[storage] macro.\n    /// You typically don't need to call this directly when writing smart contracts.\n    ///\n    /// # Arguments\n    ///\n    /// * `context` - One of `PublicContext`/`PrivateContext`/`UtilityContext`. The\n    ///               Context determines which methods of this struct will be made\n    ///               available to the calling smart contract function.\n    /// * `storage_slot` - A unique identifier for this state variable within the\n    ///                    contract. Usually, the #[storage] macro will determine an\n    ///                    appropriate storage_slot automatically. A smart contract\n    ///                    dev shouldn't have to worry about this, as it's managed\n    ///                    behind the scenes.\n    ///\n    /// docs:start:public_immutable_struct_new\n    pub fn new(\n        // Note: Passing the contexts to new(...) just to have an interface compatible with a Map.\n        context: Context,\n        storage_slot: Field,\n    ) -> Self {\n        assert(storage_slot != 0, \"Storage slot 0 not allowed. Storage slots must start from 1.\");\n        PublicImmutable { context, storage_slot }\n    }\n    // docs:end:public_immutable_struct_new\n\n    pub fn compute_initialization_nullifier(self) -> Field {\n        poseidon2_hash_with_separator(\n            [self.storage_slot],\n            GENERATOR_INDEX__INITIALIZATION_NULLIFIER,\n        )\n    }\n}\n\nimpl<T> PublicImmutable<T, &mut PublicContext> {\n    /// Initializes a PublicImmutable state variable instance with a permanent value.\n    ///\n    /// This function sets the immutable value for this state variable. It can only\n    /// be called once per PublicImmutable. Subsequent calls will fail because the\n    /// initialization nullifier will already exist.\n    ///\n    /// # Arguments\n    /// * `value` - The permanent value to store in this PublicImmutable.\n    ///\n    /// # Panics\n    /// Panics if the value is already initialized.\n    ///\n    /// # Advanced\n    ///\n    /// This function performs the following operations:\n    /// - Creates and emits an initialization nullifier to mark this storage slot\n    ///   as initialized. This prevents double-initialization.\n    /// - Wraps the value in `WithHash<T>` for efficient private reads.\n    /// - Stores the wrapped value in Aztec's public data tree.\n    ///\n    /// docs:start:public_immutable_struct_write\n    pub fn initialize(self, value: T)\n    where\n        T: Packable + Eq,\n    {\n        // We emit an initialization nullifier to indicate that the struct is initialized. This also prevents\n        // the value from being initialized again as a nullifier can be included only once.\n        let nullifier = self.compute_initialization_nullifier();\n        self.context.push_nullifier(nullifier);\n\n        self.context.storage_write(self.storage_slot, WithHash::new(value));\n    }\n    // docs:end:public_immutable_struct_write\n\n    /// Reads the permanent value stored in this PublicImmutable state variable.\n    ///\n    /// # Returns\n    /// * `T` - The permanent value stored in this PublicImmutable.\n    ///\n    /// # Panics\n    /// Panics if the value is not initialized.\n    ///\n    /// # Advanced\n    ///\n    /// This function performs the following operations:\n    /// - Checks that the state variable has been initialized by verifying the\n    ///   initialization nullifier exists\n    /// - Reads the `WithHash<T>` wrapper from public storage\n    /// - Extracts and returns the original value T\n    ///\n    /// The function will panic if called on an uninitialized PublicImmutable.\n    ///\n    /// docs:start:public_immutable_struct_read\n    pub fn read(self) -> T\n    where\n        T: Packable + Eq,\n    {\n        assert(self.is_initialized(), \"Trying to read from uninitialized PublicImmutable\");\n        WithHash::public_storage_read(*self.context, self.storage_slot)\n    }\n    // docs:end:public_immutable_struct_read\n\n    /// Reads the value stored in this PublicImmutable without checking if the value\n    /// is initialized.\n    ///\n    /// This function bypasses the initialization check and directly reads from\n    /// storage.\n    /// If the PublicImmutable has not been initialized, this will return a\n    /// zeroed value.\n    /// However, if the variable is _known_ to be initialized, this is cheaper\n    /// to call than `read`.\n    ///\n    /// # Returns\n    ///\n    /// * `T` - The value stored in this PublicImmutable, or empty/default values if\n    ///         uninitialized.\n    ///\n    pub fn read_unsafe(self) -> T\n    where\n        T: Packable + Eq,\n    {\n        WithHash::public_storage_read(*self.context, self.storage_slot)\n    }\n\n    fn is_initialized(self) -> bool {\n        let nullifier = self.compute_initialization_nullifier();\n        self.context.nullifier_exists(nullifier, self.context.this_address())\n    }\n}\n\nimpl<T> PublicImmutable<T, UtilityContext> {\n    /// Reads the permanent value stored in this PublicImmutable state variable.\n    ///\n    /// Notice that this function is executable only within a UtilityContext, which\n    /// is an unconstrained environment on the user's local device.\n    ///\n    /// # Returns\n    ///\n    /// * `T` - The permanent value stored in this PublicImmutable.\n    ///\n    pub unconstrained fn read(self) -> T\n    where\n        T: Packable + Eq,\n    {\n        // TODO(#15703): this fn should fail if the variable is not initialized\n        WithHash::utility_public_storage_read(self.context, self.storage_slot)\n    }\n}\n\nimpl<T> PublicImmutable<T, &mut PrivateContext> {\n    /// Reads the permanent value stored in this PublicImmutable from the anchor\n    /// block.\n    ///\n    /// Private functions execute asynchronously and offchain. When a user begins\n    /// private execution, their view of the chain 'branches off' from the current\n    /// public state, since public state continues to advance while they execute\n    /// privately. Therefore, private functions read from a historical snapshot of\n    /// public state rather than the current state.\n    ///\n    /// # Returns\n    ///\n    /// * `T` - The permanent value stored in this PublicImmutable at the historical\n    ///         block referenced by the private context.\n    ///\n    /// # Advanced\n    ///\n    /// This function performs a historical read using the block header from the private\n    /// context. The `WithHash` optimization is particularly valuable here because it\n    /// reduces the number of required inclusion proofs by proving membership of\n    /// only the hash instead of the full packed value.\n    ///\n    /// The historical read mechanism:\n    /// - Uses an oracle to obtain the value from the historical block\n    /// - Proves inclusion of the value's hash in the public data tree\n    /// - Proves that the root of this public data tree is correct, relative to the\n    ///   historical block header that is being referenced by this private function.\n    /// - Verifies that the oracle-provided value matches the stored hash\n    ///\n    pub fn read(self) -> T\n    where\n        T: Packable + Eq,\n    {\n        // TODO(#15703): this fn should fail if the variable is not initialized\n        WithHash::historical_public_storage_read(\n            self.context.get_block_header(),\n            self.context.this_address(),\n            self.storage_slot,\n        )\n    }\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/aztec-nr/aztec/src/state_vars/public_immutable.nr"},"187":{"source":"use crate::context::{PublicContext, UtilityContext};\nuse crate::state_vars::storage::HasStorageSlot;\nuse dep::protocol_types::traits::Packable;\n\n/// # PublicMutable\n///\n/// PublicMutable is a public state variable type for values that can be read\n/// and written within #[public] functions of your smart contract.\n///\n/// You can declare a state variable of type PublicMutable within your contract's\n/// #[storage] struct:\n///\n/// E.g.:\n/// `your_variable: PublicMutable<T, Context>`\n/// or:\n/// `your_mapping: Map<Field, PublicMutable<T, Context>>`\n///\n/// The methods of PublicMutable are:\n/// - `read`\n/// - `write`\n/// (see the methods' own doc comments for more info).\n///\n/// ## Example.\n///\n/// A voting contract's proposal count can be represented as a PublicMutable<u64>.\n/// The count can be read by anyone to see how many proposals exist, and incremented\n/// when new proposals are submitted.\n///\n/// # Generic Parameters:\n///\n/// * `T` - The type of value stored (must implement Packable).\n/// * `Context` - The execution context (PublicContext or UtilityContext).\n///\n/// # Advanced\n///\n/// Unlike private state variables which use notes, PublicMutable stores values\n/// directly in Aztec's public data tree. This enables direct read and write\n/// access to the current state during public function execution.\n///\n/// docs:start:public_mutable_struct\npub struct PublicMutable<T, Context> {\n    context: Context,\n    storage_slot: Field,\n}\n// docs:end:public_mutable_struct\n\nimpl<T, Context, let M: u32> HasStorageSlot<M> for PublicMutable<T, Context>\nwhere\n    T: Packable<N = M>,\n{\n    fn get_storage_slot(self) -> Field {\n        self.storage_slot\n    }\n}\n\nimpl<T, Context> PublicMutable<T, Context> {\n    /// Initializes a new PublicMutable state variable.\n    ///\n    /// This function is usually automatically called within the #[storage] macro.\n    /// You typically don't need to call this directly when writing smart contracts.\n    ///\n    /// # Arguments\n    ///\n    /// * `context` - One of `PublicContext`/`UtilityContext`. The Context determines\n    ///               which methods of this struct will be made available to the calling\n    ///               smart contract function.\n    /// * `storage_slot` - A unique identifier for this state variable within the\n    ///                    contract. Usually, the #[storage] macro will determine an\n    ///                    appropriate storage_slot automatically. A smart contract\n    ///                    dev shouldn't have to worry about this, as it's managed\n    ///                    behind the scenes.\n    ///\n    /// docs:start:public_mutable_struct_new\n    pub fn new(\n        // Note: Passing the contexts to new(...) just to have an interface compatible with a Map.\n        context: Context,\n        storage_slot: Field,\n    ) -> Self {\n        assert(storage_slot != 0, \"Storage slot 0 not allowed. Storage slots must start from 1.\");\n        PublicMutable { context, storage_slot }\n    }\n    // docs:end:public_mutable_struct_new\n}\n\nimpl<T> PublicMutable<T, &mut PublicContext> {\n    /// Reads the current value stored in this PublicMutable state variable.\n    ///\n    /// # Returns\n    ///\n    /// * `T` - The current value stored in this PublicMutable.\n    ///\n    /// docs:start:public_mutable_struct_read\n    pub fn read(self) -> T\n    where\n        T: Packable,\n    {\n        self.context.storage_read(self.storage_slot)\n    }\n    // docs:end:public_mutable_struct_read\n\n    /// Writes a new value to this PublicMutable state variable.\n    ///\n    /// # Arguments\n    ///\n    /// * `value` - The new value to store in this PublicMutable.\n    ///\n    /// # Advanced\n    ///\n    /// This function updates the value stored in Aztec's public data tree.\n    /// The new value becomes immediately available to subsequent reads within\n    /// the same transaction.\n    ///\n    /// docs:start:public_mutable_struct_write\n    pub fn write(self, value: T)\n    where\n        T: Packable,\n    {\n        self.context.storage_write(self.storage_slot, value);\n    }\n    // docs:end:public_mutable_struct_write\n}\n\nimpl<T> PublicMutable<T, UtilityContext> {\n    /// Reads the current value stored in this PublicMutable state variable.\n    ///\n    /// Notice that this function is executable only within a UtilityContext, which\n    /// is an unconstrained environment on the user's local device.\n    ///\n    /// # Returns\n    ///\n    /// * `T` - The current value stored in this PublicMutable.\n    ///\n    pub unconstrained fn read(self) -> T\n    where\n        T: Packable,\n    {\n        self.context.storage_read(self.storage_slot)\n    }\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/aztec-nr/aztec/src/state_vars/public_mutable.nr"},"219":{"source":"use crate::{\n    context::{PublicContext, UtilityContext},\n    history::public_storage::PublicStorageHistoricalRead,\n    oracle,\n};\nuse dep::protocol_types::{\n    abis::block_header::BlockHeader, address::AztecAddress, hash::poseidon2_hash, traits::Packable,\n};\n\n/// A struct that allows for efficient reading of value `T` from public storage in private.\n///\n/// The efficient reads are achieved by verifying large values through a single hash check\n/// and then proving inclusion only of the hash in public storage. This reduces the number\n/// of required tree inclusion proofs from `M` to 1.\n///\n/// # Type Parameters\n/// - `T`: The underlying type being wrapped, must implement `Packable<N>`\n/// - `M`: The number of field elements required to pack values of type `T`\npub struct WithHash<T, let M: u32> {\n    value: T,\n    packed: [Field; M],\n    hash: Field,\n}\n\nimpl<T, let M: u32> WithHash<T, M>\nwhere\n    T: Packable<N = M> + Eq,\n{\n    pub fn new(value: T) -> Self {\n        let packed = value.pack();\n        Self { value, packed, hash: poseidon2_hash(packed) }\n    }\n\n    pub fn get_value(self) -> T {\n        self.value\n    }\n\n    pub fn get_hash(self) -> Field {\n        self.hash\n    }\n\n    pub fn public_storage_read(context: PublicContext, storage_slot: Field) -> T {\n        context.storage_read(storage_slot)\n    }\n\n    pub unconstrained fn utility_public_storage_read(\n        context: UtilityContext,\n        storage_slot: Field,\n    ) -> T {\n        context.storage_read(storage_slot)\n    }\n\n    pub fn historical_public_storage_read(\n        header: BlockHeader,\n        address: AztecAddress,\n        storage_slot: Field,\n    ) -> T {\n        let historical_block_number = header.global_variables.block_number;\n\n        // We could simply produce historical inclusion proofs for each field in `packed`, but that would require one\n        // full sibling path per storage slot (since due to kernel siloing the storage is not contiguous). Instead, we\n        // get an oracle to provide us the values, and instead we prove inclusion of their hash, which is both a much\n        // smaller proof (a single slot), and also independent of the size of T (except in that we need to pack and hash T).\n        let hint = WithHash::new(\n            // Safety: We verify that a hash of the hint/packed data matches the stored hash.\n            unsafe {\n                oracle::storage::storage_read(address, storage_slot, historical_block_number)\n            },\n        );\n\n        let hash = header.public_storage_historical_read(storage_slot + M as Field, address);\n\n        if hash != 0 {\n            assert_eq(hash, hint.get_hash(), \"Hint values do not match hash\");\n        } else {\n            // The hash slot can only hold a zero if it is uninitialized. Therefore, the hints must then be zero\n            // (i.e. the default value for public storage) as well.\n            assert_eq(\n                hint.get_value(),\n                T::unpack(std::mem::zeroed()),\n                \"Non-zero hint for zero hash\",\n            );\n        };\n\n        hint.get_value()\n    }\n}\n\n// Note: I don't derive Packable on `WithHash` because `derive_serialize` function does not support setting \"N = M\"\n// as I do here 3 lines below. This could be worked around by placing the \"where\" clause directly on the `WithHash`\n// struct, but Jake mentioned that the syntax is not expected to be supported at least until Noir 1.0.\n// Relevant discussion on Slack:\n// https://aztecprotocol.slack.com/archives/C04QF64EDNV/p1752593876160699?thread_ts=1752589887.955379&cid=C04QF64EDNV\nimpl<T, let M: u32> Packable for WithHash<T, M>\nwhere\n    T: Packable<N = M>,\n{\n    let N: u32 = M + 1;\n\n    fn pack(self) -> [Field; Self::N] {\n        let mut result: [Field; Self::N] = std::mem::zeroed();\n        for i in 0..M {\n            result[i] = self.packed[i];\n        }\n        result[M] = self.hash;\n\n        result\n    }\n\n    fn unpack(packed: [Field; Self::N]) -> Self {\n        let mut value_packed = [0; M];\n        for i in 0..M {\n            value_packed[i] = packed[i];\n        }\n        let hash = packed[M];\n\n        Self { value: T::unpack(value_packed), packed: value_packed, hash }\n    }\n}\n\nmod test {\n    use crate::{\n        test::{helpers::test_environment::TestEnvironment, mocks::mock_struct::MockStruct},\n        utils::with_hash::WithHash,\n    };\n    use dep::protocol_types::hash::poseidon2_hash;\n    use dep::protocol_types::traits::{Packable, ToField};\n    use dep::std::test::OracleMock;\n\n    global STORAGE_SLOT: Field = 47;\n\n    #[test]\n    unconstrained fn create_and_recover() {\n        let value = MockStruct { a: 5, b: 3 };\n        let value_with_hash = WithHash::new(value);\n        let recovered = WithHash::unpack(value_with_hash.pack());\n\n        assert_eq(recovered.value, value);\n        assert_eq(recovered.packed, value.pack());\n        assert_eq(recovered.hash, poseidon2_hash(value.pack()));\n    }\n\n    #[test]\n    unconstrained fn read_uninitialized_value() {\n        let env = TestEnvironment::new();\n\n        env.private_context(|context| {\n            let result = WithHash::<MockStruct, _>::historical_public_storage_read(\n                context.historical_header,\n                context.this_address(),\n                STORAGE_SLOT,\n            );\n\n            assert_eq(result, std::mem::zeroed());\n        });\n    }\n\n    #[test]\n    unconstrained fn read_initialized_value() {\n        let env = TestEnvironment::new();\n\n        let value = MockStruct { a: 5, b: 3 };\n        let value_with_hash = WithHash::new(value);\n\n        env.public_context(|context| { context.storage_write(STORAGE_SLOT, value_with_hash); });\n\n        env.private_context(|context| {\n            let result = WithHash::<MockStruct, _>::historical_public_storage_read(\n                context.historical_header,\n                context.this_address(),\n                STORAGE_SLOT,\n            );\n            assert_eq(result, value);\n        });\n    }\n\n    #[test(should_fail_with = \"Non-zero hint for zero hash\")]\n    unconstrained fn bad_hint_uninitialized_value() {\n        let env = TestEnvironment::new();\n\n        env.private_context(|context| {\n            let block_header = context.historical_header;\n            let address = context.this_address();\n\n            // Mock the oracle to return a non-zero hint/packed value\n            let value_packed = MockStruct { a: 1, b: 1 }.pack();\n            let _ = OracleMock::mock(\"utilityStorageRead\")\n                .with_params((\n                    address.to_field(), STORAGE_SLOT, block_header.global_variables.block_number,\n                    value_packed.len(),\n                ))\n                .returns(value_packed)\n                .times(1);\n\n            // This should fail because the hint value is non-zero and the hash is zero (default value of storage)\n            let _ = WithHash::<MockStruct, _>::historical_public_storage_read(\n                block_header,\n                address,\n                STORAGE_SLOT,\n            );\n        });\n    }\n\n    #[test(should_fail_with = \"Hint values do not match hash\")]\n    unconstrained fn bad_hint_initialized_value() {\n        let env = TestEnvironment::new();\n\n        env.public_context(|context| {\n            // Write the value and hash separately so that the hash is wrong\n            let value = MockStruct { a: 5, b: 3 };\n            context.storage_write(STORAGE_SLOT, value);\n\n            let incorrect_hash = 13;\n            let hash_storage_slot = STORAGE_SLOT + (value.pack().len() as Field);\n            context.storage_write(hash_storage_slot, [incorrect_hash]);\n        });\n\n        env.private_context(|context| {\n            let _ = WithHash::<MockStruct, _>::historical_public_storage_read(\n                context.historical_header,\n                context.this_address(),\n                STORAGE_SLOT,\n            );\n        });\n    }\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/aztec-nr/aztec/src/utils/with_hash.nr"},"226":{"source":"use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n","path":"/home/jimjim/nargo/github.com/noir-lang/poseidon/v0.1.1/src/poseidon2.nr"},"316":{"source":"use crate::{\n    abis::{\n        contract_class_function_leaf_preimage::ContractClassFunctionLeafPreimage,\n        function_selector::FunctionSelector,\n        note_hash::ScopedNoteHash,\n        nullifier::ScopedNullifier,\n        private_log::{PrivateLog, PrivateLogData},\n        side_effect::{OrderedValue, scoped::Scoped},\n    },\n    address::{AztecAddress, EthAddress},\n    constants::{\n        CONTRACT_CLASS_LOG_SIZE_IN_FIELDS, FUNCTION_TREE_HEIGHT, GENERATOR_INDEX__NOTE_HASH_NONCE,\n        GENERATOR_INDEX__OUTER_NULLIFIER, GENERATOR_INDEX__SILOED_NOTE_HASH,\n        GENERATOR_INDEX__UNIQUE_NOTE_HASH, TWO_POW_64,\n    },\n    merkle_tree::root::root_from_sibling_path,\n    messaging::l2_to_l1_message::L2ToL1Message,\n    poseidon2::Poseidon2Sponge,\n    traits::{FromField, Hash, ToField},\n    utils::field::{field_from_bytes, field_from_bytes_32_trunc},\n};\nuse std::embedded_curve_ops::EmbeddedCurveScalar;\n\npub fn sha256_to_field<let N: u32>(bytes_to_hash: [u8; N]) -> Field {\n    let sha256_hashed = sha256::digest(bytes_to_hash);\n    let hash_in_a_field = field_from_bytes_32_trunc(sha256_hashed);\n\n    hash_in_a_field\n}\n\npub fn private_functions_root_from_siblings(\n    selector: FunctionSelector,\n    vk_hash: Field,\n    function_leaf_index: Field,\n    function_leaf_sibling_path: [Field; FUNCTION_TREE_HEIGHT],\n) -> Field {\n    let function_leaf_preimage = ContractClassFunctionLeafPreimage { selector, vk_hash };\n    let function_leaf = function_leaf_preimage.hash();\n    root_from_sibling_path(\n        function_leaf,\n        function_leaf_index,\n        function_leaf_sibling_path,\n    )\n}\n\npub fn compute_note_hash_nonce(first_nullifier_in_tx: Field, note_index_in_tx: u32) -> Field {\n    // Hashing the first nullifier with note index in tx is guaranteed to be unique (because all nullifiers are also\n    // unique).\n    poseidon2_hash_with_separator(\n        [first_nullifier_in_tx, note_index_in_tx as Field],\n        GENERATOR_INDEX__NOTE_HASH_NONCE,\n    )\n}\n\npub fn compute_unique_note_hash(note_nonce: Field, siloed_note_hash: Field) -> Field {\n    let inputs = [note_nonce, siloed_note_hash];\n    poseidon2_hash_with_separator(inputs, GENERATOR_INDEX__UNIQUE_NOTE_HASH)\n}\n\npub fn compute_nonce_and_unique_note_hash(\n    siloed_note_hash: Field,\n    first_nullifier: Field,\n    note_index_in_tx: u32,\n) -> Field {\n    let note_nonce = compute_note_hash_nonce(first_nullifier, note_index_in_tx);\n    compute_unique_note_hash(note_nonce, siloed_note_hash)\n}\n\npub fn compute_siloed_note_hash(app: AztecAddress, note_hash: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), note_hash],\n        GENERATOR_INDEX__SILOED_NOTE_HASH,\n    )\n}\n\n/// Computes unique note hashes from siloed note hashes\npub fn compute_unique_siloed_note_hash(\n    siloed_note_hash: Field,\n    first_nullifier: Field,\n    note_index_in_tx: u32,\n) -> Field {\n    if siloed_note_hash == 0 {\n        0\n    } else {\n        compute_nonce_and_unique_note_hash(siloed_note_hash, first_nullifier, note_index_in_tx)\n    }\n}\n\n/// Siloing in the context of Aztec refers to the process of hashing a note hash with a contract address (this way\n/// the note hash is scoped to a specific contract). This is used to prevent intermingling of notes between contracts.\npub fn silo_note_hash(note_hash: ScopedNoteHash) -> Field {\n    if note_hash.contract_address.is_zero() {\n        0\n    } else {\n        compute_siloed_note_hash(note_hash.contract_address, note_hash.value())\n    }\n}\n\npub fn compute_siloed_nullifier(app: AztecAddress, nullifier: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), nullifier],\n        GENERATOR_INDEX__OUTER_NULLIFIER,\n    )\n}\n\npub fn silo_nullifier(nullifier: ScopedNullifier) -> Field {\n    // Q: shouldn't we be checking whether the _whole_ nullifier is empty?\n    // A: We don't have to. The init and inner circuits add contract address to non-empty nullifiers.\n    // So we know we should silo it if the contract address is not empty.\n    if nullifier.contract_address.is_zero() {\n        // Q: I don't understand this comment. We could still compute a siloed nullifier from a zero contract address.\n        nullifier.value() // Return value instead of 0 because the first nullifier's contract address is zero.\n    } else {\n        compute_siloed_nullifier(nullifier.contract_address, nullifier.value())\n    }\n}\n\npub fn compute_siloed_private_log_field(contract_address: AztecAddress, field: Field) -> Field {\n    poseidon2_hash([contract_address.to_field(), field])\n}\n\npub fn silo_private_log(private_log: Scoped<PrivateLogData>) -> PrivateLog {\n    if private_log.contract_address.is_zero() {\n        private_log.inner.log\n    } else {\n        let mut fields = private_log.inner.log.fields;\n        fields[0] = compute_siloed_private_log_field(private_log.contract_address, fields[0]);\n        PrivateLog::new(fields, private_log.inner.log.length)\n    }\n}\n\npub fn compute_contract_class_log_hash(log: [Field; CONTRACT_CLASS_LOG_SIZE_IN_FIELDS]) -> Field {\n    poseidon2_hash(log)\n}\n\npub fn compute_app_secret_key(\n    master_secret_key: EmbeddedCurveScalar,\n    app_address: AztecAddress,\n    app_secret_generator: Field,\n) -> Field {\n    poseidon2_hash_with_separator(\n        [master_secret_key.hi, master_secret_key.lo, app_address.to_field()],\n        app_secret_generator,\n    )\n}\n\npub fn merkle_hash(left: Field, right: Field) -> Field {\n    poseidon2_hash([left, right])\n}\n\npub fn compute_l2_to_l1_hash(\n    contract_address: AztecAddress,\n    recipient: EthAddress,\n    content: Field,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    let contract_address_bytes: [u8; 32] = contract_address.to_field().to_be_bytes();\n    let recipient_bytes: [u8; 20] = recipient.to_be_bytes();\n    let content_bytes: [u8; 32] = content.to_be_bytes();\n    let rollup_version_id_bytes: [u8; 32] = rollup_version_id.to_be_bytes();\n    let chain_id_bytes: [u8; 32] = chain_id.to_be_bytes();\n\n    let mut bytes: [u8; 148] = std::mem::zeroed();\n    for i in 0..32 {\n        bytes[i] = contract_address_bytes[i];\n        bytes[i + 32] = rollup_version_id_bytes[i];\n        // 64 - 84 are for recipient.\n        bytes[i + 84] = chain_id_bytes[i];\n        bytes[i + 116] = content_bytes[i];\n    }\n\n    for i in 0..20 {\n        bytes[64 + i] = recipient_bytes[i];\n    }\n\n    sha256_to_field(bytes)\n}\n\npub fn silo_l2_to_l1_message(\n    msg: Scoped<L2ToL1Message>,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    if msg.contract_address.is_zero() {\n        0\n    } else {\n        compute_l2_to_l1_hash(\n            msg.contract_address,\n            msg.inner.recipient,\n            msg.inner.content,\n            rollup_version_id,\n            chain_id,\n        )\n    }\n}\n\n/// Computes sha256 hash of 2 input fields.\n///\n/// @returns A truncated field (i.e., the first byte is always 0).\npub fn accumulate_sha256(v0: Field, v1: Field) -> Field {\n    // Concatenate two fields into 32 x 2 = 64 bytes\n    let v0_as_bytes: [u8; 32] = v0.to_be_bytes();\n    let v1_as_bytes: [u8; 32] = v1.to_be_bytes();\n    let hash_input_flattened = v0_as_bytes.concat(v1_as_bytes);\n\n    sha256_to_field(hash_input_flattened)\n}\n\n#[inline_always]\npub fn pedersen_hash<let N: u32>(inputs: [Field; N], hash_index: u32) -> Field {\n    std::hash::pedersen_hash_with_separator(inputs, hash_index)\n}\n\npub fn poseidon2_hash<let N: u32>(inputs: [Field; N]) -> Field {\n    poseidon::poseidon2::Poseidon2::hash(inputs, N)\n}\n\n#[no_predicates]\npub fn poseidon2_hash_with_separator<let N: u32, T>(inputs: [Field; N], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let inputs_with_separator = [separator.to_field()].concat(inputs);\n    poseidon2_hash(inputs_with_separator)\n}\n\n// Performs a fixed length hash with a subarray of the given input.\n// Useful for SpongeBlob in which we aborb M things and want to check it vs a hash of M elts of an N-len array.\n// Using stdlib poseidon, this will always absorb an extra 1 as a 'variable' hash, and not match spongeblob.squeeze()\n// or any ts implementation. Also checks that any remaining elts not hashed are empty.\n#[no_predicates]\npub fn poseidon2_hash_subarray<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_chunks(input, in_len, false);\n    sponge.squeeze()\n}\n\n// NB the below is the same as poseidon::poseidon2::Poseidon2::hash(), but replacing a range check with a bit check,\n// and absorbing in chunks of 3 below.\n#[no_predicates]\npub fn poseidon2_cheaper_variable_hash<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_chunks(input, in_len, true);\n    // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n    // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n    // fixed-length and variable-length hashes do not collide)\n    if in_len != N {\n        sponge.absorb(1);\n    }\n    sponge.squeeze()\n}\n\n// The below fn reduces gates of a conditional poseidon2 hash by approx 3x (thank you ~* Giant Brain Dev @IlyasRidhuan *~ for the idea)\n// Why? Because when we call stdlib poseidon, we call absorb for each item. When absorbing is conditional, it seems the compiler does not know\n// what cache_size will be when calling absorb, so it assigns the permutation gates for /each i/ rather than /every 3rd i/, which is actually required.\n// The below code forces the compiler to:\n//  - absorb normally up to 2 times to set cache_size to 1\n//  - absorb in chunks of 3 to ensure perm. only happens every 3rd absorb\n//  - absorb normally up to 2 times to add any remaining values to the hash\n// In fixed len hashes, the compiler is able to tell that it will only need to perform the permutation every 3 absorbs.\n// NB: it also replaces unnecessary range checks (i < thing) with a bit check (&= i != thing), which alone reduces the gates of a var. hash by half.\n\n#[no_predicates]\nfn poseidon2_absorb_chunks<let N: u32>(\n    input: [Field; N],\n    in_len: u32,\n    variable: bool,\n) -> Poseidon2Sponge {\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    // Even though shift is always 1 here, if we input in_len = 0 we get an underflow\n    // since we cannot isolate computation branches. The below is just to avoid that.\n    let shift = if in_len == 0 { 0 } else { 1 };\n    if in_len != 0 {\n        // cache_size = 0, init absorb\n        sponge.cache[0] = input[0];\n        sponge.cache_size = 1;\n        // shift = num elts already added to make cache_size 1 = 1 for a fresh sponge\n        // M = max_chunks = (N - 1 - (N - 1) % 3) / 3: (must be written as a fn of N to compile)\n        // max_remainder = (N - 1) % 3;\n        // max_chunks = (N - 1 - max_remainder) / 3;\n        sponge = poseidon2_absorb_chunks_loop::<N, (N - 1 - (N - 1) % 3) / 3>(\n            sponge,\n            input,\n            in_len,\n            variable,\n            shift,\n        );\n    }\n    sponge\n}\n\n// NB: If it's not required to check that the non-absorbed elts of 'input' are 0s, set skip_0_check=true\n#[no_predicates]\npub fn poseidon2_absorb_chunks_existing_sponge<let N: u32>(\n    in_sponge: Poseidon2Sponge,\n    input: [Field; N],\n    in_len: u32,\n    skip_0_check: bool,\n) -> Poseidon2Sponge {\n    let mut sponge = in_sponge;\n    // 'shift' is to account for already added inputs\n    let mut shift = 0;\n    // 'stop' is to avoid an underflow when inputting in_len = 0\n    let mut stop = false;\n    for i in 0..3 {\n        if shift == in_len {\n            stop = true;\n        }\n        if (sponge.cache_size != 1) & (!stop) {\n            sponge.absorb(input[i]);\n            shift += 1;\n        }\n    }\n    sponge = if stop {\n        sponge\n    } else {\n        // max_chunks = (N - (N % 3)) / 3;\n        poseidon2_absorb_chunks_loop::<N, (N - (N % 3)) / 3>(\n            sponge,\n            input,\n            in_len,\n            skip_0_check,\n            shift,\n        )\n    };\n    sponge\n}\n\n// The below is the loop to absorb elts into a poseidon sponge in chunks of 3\n// shift - the num of elts already absorbed to ensure the sponge's cache_size = 1\n// M - the max number of chunks required to absorb N things (must be comptime to compile)\n// NB: The 0 checks ('Found non-zero field...') are messy, but having a separate loop over N to check\n// for 0s costs 3N gates. Current approach is approx 2N gates.\n#[no_predicates]\nfn poseidon2_absorb_chunks_loop<let N: u32, let M: u32>(\n    in_sponge: Poseidon2Sponge,\n    input: [Field; N],\n    in_len: u32,\n    variable: bool,\n    shift: u32,\n) -> Poseidon2Sponge {\n    assert(in_len <= N, \"Given in_len to absorb is larger than the input array len\");\n    // When we have an existing sponge, we may have a shift of 0, and the final 'k+2' below = N\n    // The below avoids an overflow\n    let skip_last = 3 * M == N;\n    // Writing in_sponge: &mut does not compile\n    let mut sponge = in_sponge;\n    let mut should_add = true;\n    // The num of things left over after absorbing in 3s\n    let remainder = (in_len - shift) % 3;\n    // The num of chunks of 3 to absorb (maximum M)\n    let chunks = (in_len - shift - remainder) / 3;\n    for i in 0..M {\n        // Now we loop through cache size = 1 -> 3\n        should_add &= i != chunks;\n        // This is the index at the start of the chunk (for readability)\n        let k = 3 * i + shift;\n        if should_add {\n            // cache_size = 1, 2 => just assign\n            sponge.cache[1] = input[k];\n            sponge.cache[2] = input[k + 1];\n            // cache_size = 3 => duplex + perm\n            for j in 0..3 {\n                sponge.state[j] += sponge.cache[j];\n            }\n            sponge.state = std::hash::poseidon2_permutation(sponge.state, 4);\n            sponge.cache[0] = input[k + 2];\n            // cache_size is now 1 again, repeat loop\n        } else if (!variable) & (i != chunks) {\n            // if we are hashing a fixed len array which is a subarray, we check the remaining elts are 0\n            // NB: we don't check at i == chunks, because that chunk contains elts to be absorbed or checked below\n            let last_0 = if (i == M - 1) & (skip_last) {\n                0\n            } else {\n                input[k + 2]\n            };\n            let all_0 = (input[k] == 0) & (input[k + 1] == 0) & (last_0 == 0);\n            assert(all_0, \"Found non-zero field after breakpoint\");\n        }\n    }\n    // we have 'remainder' num of items left to absorb\n    should_add = true;\n    // below is to avoid overflows (i.e. if inlen is close to N)\n    let mut should_check = !variable;\n    for i in 0..3 {\n        should_add &= i != remainder;\n        should_check &= in_len - remainder + i != N;\n        if should_add {\n            // we want to absorb the final 'remainder' items\n            sponge.absorb(input[in_len - remainder + i]);\n        } else if should_check {\n            assert_eq(input[in_len - remainder + i], 0, \"Found non-zero field after breakpoint\");\n        }\n    }\n    sponge\n}\n\npub fn poseidon2_hash_with_separator_slice<T>(inputs: [Field], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let in_len = inputs.len() + 1;\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\n// This function is  unconstrained because it is intended to be used in unconstrained context only as\n// in constrained contexts it would be too inefficient.\npub unconstrained fn poseidon2_hash_with_separator_bounded_vec<let N: u32, T>(\n    inputs: BoundedVec<Field, N>,\n    separator: T,\n) -> Field\nwhere\n    T: ToField,\n{\n    let in_len = inputs.len() + 1;\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs.get(i));\n    }\n\n    sponge.squeeze()\n}\n\n#[no_predicates]\npub fn poseidon2_hash_bytes<let N: u32>(inputs: [u8; N]) -> Field {\n    let mut fields = [0; (N + 30) / 31];\n    let mut field_index = 0;\n    let mut current_field = [0; 31];\n    for i in 0..inputs.len() {\n        let index = i % 31;\n        current_field[index] = inputs[i];\n        if index == 30 {\n            fields[field_index] = field_from_bytes(current_field, false);\n            current_field = [0; 31];\n            field_index += 1;\n        }\n    }\n    if field_index != fields.len() {\n        fields[field_index] = field_from_bytes(current_field, false);\n    }\n    poseidon2_hash(fields)\n}\n\n#[test]\nfn poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let sub_chunk_hash = poseidon2_hash_subarray(input, in_len);\n    let fixed_len_hash = poseidon::poseidon2::Poseidon2::hash(fixed_input, fixed_input.len());\n    assert(sub_chunk_hash == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_matches_variable() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let variable_chunk_hash = poseidon2_cheaper_variable_hash(input, in_len);\n    let variable_len_hash = poseidon::poseidon2::Poseidon2::hash(input, in_len);\n    assert(variable_chunk_hash == variable_len_hash);\n}\n\n#[test]\nfn existing_sponge_poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    // absorb 250 of the 501 things\n    let empty_sponge = Poseidon2Sponge::new((in_len as Field) * TWO_POW_64);\n    let first_sponge = poseidon2_absorb_chunks_existing_sponge(empty_sponge, input, 250, true);\n    // now absorb the final 251 (since they are all 3s, im being lazy and not making a new array)\n    let mut final_sponge = poseidon2_absorb_chunks_existing_sponge(first_sponge, input, 251, true);\n    let fixed_len_hash = Poseidon2Sponge::hash(fixed_input, fixed_input.len());\n    assert(final_sponge.squeeze() == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_empty_inputs() {\n    let in_len = 0;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut constructed_empty_sponge = poseidon2_absorb_chunks(input, in_len, true);\n    let mut first_sponge =\n        poseidon2_absorb_chunks_existing_sponge(constructed_empty_sponge, input, in_len, true);\n    assert(first_sponge.squeeze() == constructed_empty_sponge.squeeze());\n}\n\n#[test]\nfn smoke_sha256_to_field() {\n    let full_buffer = [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n        25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n        71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,\n        94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n    ];\n    let result = sha256_to_field(full_buffer);\n\n    assert(result == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184c7);\n\n    // to show correctness of the current ver (truncate one byte) vs old ver (mod full bytes):\n    let result_bytes = sha256::digest(full_buffer);\n    let truncated_field = crate::utils::field::field_from_bytes_32_trunc(result_bytes);\n    assert(truncated_field == result);\n    let mod_res = result + (result_bytes[31] as Field);\n    assert(mod_res == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184e0);\n}\n\n#[test]\nfn compute_l2_l1_hash() {\n    // All zeroes\n    let hash_result =\n        compute_l2_to_l1_hash(AztecAddress::from_field(0), EthAddress::zero(), 0, 0, 0);\n    assert(hash_result == 0x3b18c58c739716e76429634a61375c45b3b5cd470c22ab6d3e14cee23dd992);\n\n    // Non-zero case\n    let hash_result = compute_l2_to_l1_hash(\n        AztecAddress::from_field(1),\n        EthAddress::from_field(3),\n        5,\n        2,\n        4,\n    );\n    assert(hash_result == 0xaab2a5828156782b12a1dc6f336e2bc627eb1b9514b02d511f66296990c050);\n}\n\n#[test]\nfn silo_l2_to_l1_message_matches_typescript() {\n    let version = 4;\n    let chainId = 5;\n\n    let hash = silo_l2_to_l1_message(\n        L2ToL1Message { recipient: EthAddress::from_field(1), content: 2 }.scope(\n            AztecAddress::from_field(3),\n        ),\n        version,\n        chainId,\n    );\n\n    // The following value was generated by `yarn-project/stdlib/src/hash/hash.test.ts`\n    let hash_from_typescript = 0x0081edf209e087ad31b3fd24263698723d57190bd1d6e9fe056fc0c0a68ee661;\n\n    assert_eq(hash, hash_from_typescript);\n}\n\n#[test]\nunconstrained fn poseidon2_hash_with_separator_bounded_vec_matches_non_bounded_vec_version() {\n    let inputs = BoundedVec::<Field, 4>::from_array([1, 2, 3]);\n    let separator = 42;\n\n    // Hash using bounded vec version\n    let bounded_result = poseidon2_hash_with_separator_bounded_vec(inputs, separator);\n\n    // Hash using regular version\n    let regular_result = poseidon2_hash_with_separator([1, 2, 3], separator);\n\n    // Results should match\n    assert_eq(bounded_result, regular_result);\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/noir-protocol-circuits/crates/types/src/hash.nr"},"344":{"source":"use crate::{hash::poseidon2_hash, traits::ToField};\n\npub fn derive_storage_slot_in_map<K>(storage_slot: Field, key: K) -> Field\nwhere\n    K: ToField,\n{\n    poseidon2_hash([storage_slot, key.to_field()])\n}\n\nmod test {\n    use crate::{address::AztecAddress, storage::map::derive_storage_slot_in_map, traits::FromField};\n\n    #[test]\n    fn test_derive_storage_slot_in_map_matches_typescript() {\n        let map_slot = 0x132258fb6962c4387ba659d9556521102d227549a386d39f0b22d1890d59c2b5;\n        let key = AztecAddress::from_field(\n            0x302dbc2f9b50a73283d5fb2f35bc01eae8935615817a0b4219a057b2ba8a5a3f,\n        );\n\n        let slot = derive_storage_slot_in_map(map_slot, key);\n\n        // The following value was generated by `map_slot.test.ts`\n        let slot_from_typescript =\n            0x15b9fe39449affd8b377461263e9d2b610b9ad40580553500b4e41d9cbd887ac;\n\n        assert_eq(slot, slot_from_typescript);\n    }\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/noir-protocol-circuits/crates/types/src/storage/map.nr"},"377":{"source":"pub fn field_from_bytes<let N: u32>(bytes: [u8; N], big_endian: bool) -> Field {\n    assert(bytes.len() < 32, \"field_from_bytes: N must be less than 32\");\n    let mut as_field = 0;\n    let mut offset = 1;\n    for i in 0..N {\n        let mut index = i;\n        if big_endian {\n            index = N - i - 1;\n        }\n        as_field += (bytes[index] as Field) * offset;\n        offset *= 256;\n    }\n\n    as_field\n}\n\n// Convert a 32 byte array to a field element by truncating the final byte\npub fn field_from_bytes_32_trunc(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..15 {\n        // covers bytes 16..30 (31 is truncated and ignored)\n        low = low + (bytes32[15 + 15 - i] as Field) * v;\n        v = v * 256;\n        // covers bytes 0..14\n        high = high + (bytes32[14 - i] as Field) * v;\n    }\n    // covers byte 15\n    low = low + (bytes32[15] as Field) * v;\n\n    low + high * v\n}\n\n// TODO: This currently only exists to aid point compression in compress_to_blob_commitment().\n// Once compression is part of BigCurve it can either be removed or optimized to be used elsewhere.\npub fn byte_to_bits_be(byte: u8) -> [u1; 8] {\n    let mut mut_byte = byte;\n    let mut bits: [u1; 8] = [0; 8];\n    for i in 0..8 {\n        bits[7 - i] = (mut_byte & 1) as u1;\n        mut_byte >>= 1;\n    }\n    bits\n}\n\n// TODO to radix returns u8, so we cannot use bigger radixes. It'd be ideal to use a radix of the maximum range-constrained integer noir supports\npub fn full_field_less_than(lhs: Field, rhs: Field) -> bool {\n    lhs.lt(rhs)\n}\n\npub fn full_field_greater_than(lhs: Field, rhs: Field) -> bool {\n    rhs.lt(lhs)\n}\n\npub fn min(f1: Field, f2: Field) -> Field {\n    if f1.lt(f2) {\n        f1\n    } else {\n        f2\n    }\n}\n\nglobal C1: u32 = 28;\nglobal C3: Field = 40770029410420498293352137776570907027550720424234931066070132305055;\nglobal C5: Field = 19103219067921713944291392827692070036145651957329286315305642004821462161904;\n\npub(crate) fn pow(x: Field, y: Field) -> Field {\n    let mut r = 1 as Field;\n    let b: [u1; 254] = y.to_le_bits();\n\n    for i in 0..254 {\n        r *= r;\n        r *= (b[254 - 1 - i] as Field) * x + (1 - b[254 - 1 - i] as Field);\n    }\n\n    r\n}\n\n// Tonelli-Shanks algorithm for computing the square root of a Field element.\n// Requires C1 = max{c: 2^c divides (p-1)}, where p is the order of Field\n// as well as C3 = (C2 - 1)/2, where C2 = (p-1)/(2^c1),\n// and C5 = ZETA^C2, where ZETA is a non-square element of Field.\n// These are pre-computed above as globals.\npub(crate) fn sqrt(x: Field) -> Field {\n    let mut z = pow(x, C3);\n    let mut t = z * z * x;\n    z *= x;\n    let mut b = t;\n    let mut c = C5;\n\n    for i in 0..(C1 - 1) {\n        for _j in 1..(C1 - i - 1) {\n            b *= b;\n        }\n\n        z *= if b == 1 { 1 } else { c };\n\n        c *= c;\n\n        t *= if b == 1 { 1 } else { c };\n\n        b = t;\n    }\n\n    z\n}\n\n#[test]\nunconstrained fn bytes_field_test() {\n    // Tests correctness of field_from_bytes_32_trunc against existing methods\n    // Bytes representing 0x543e0a6642ffeb8039296861765a53407bba62bd1c97ca43374de950bbe0a7\n    let inputs = [\n        84, 62, 10, 102, 66, 255, 235, 128, 57, 41, 104, 97, 118, 90, 83, 64, 123, 186, 98, 189, 28,\n        151, 202, 67, 55, 77, 233, 80, 187, 224, 167,\n    ];\n    let field = field_from_bytes(inputs, true);\n    let return_bytes: [u8; 31] = field.to_be_bytes();\n    assert_eq(inputs, return_bytes);\n    // 32 bytes - we remove the final byte, and check it matches the field\n    let inputs2 = [\n        84, 62, 10, 102, 66, 255, 235, 128, 57, 41, 104, 97, 118, 90, 83, 64, 123, 186, 98, 189, 28,\n        151, 202, 67, 55, 77, 233, 80, 187, 224, 167, 158,\n    ];\n    let field2 = field_from_bytes_32_trunc(inputs2);\n    let return_bytes2: [u8; 31] = field.to_be_bytes();\n\n    assert_eq(return_bytes2, return_bytes);\n    assert_eq(field2, field);\n}\n\n#[test]\nunconstrained fn max_field_test() {\n    // Tests the hardcoded value in constants.nr vs underlying modulus\n    // NB: We can't use 0-1 in constants.nr as it will be transpiled incorrectly to ts and sol constants files\n    let max_value = crate::constants::MAX_FIELD_VALUE;\n    assert_eq(max_value, 0 - 1);\n    // modulus == 0 is tested elsewhere, so below is more of a sanity check\n    let max_bytes: [u8; 32] = max_value.to_be_bytes();\n    let mod_bytes = std::field::modulus_be_bytes();\n    for i in 0..31 {\n        assert_eq(max_bytes[i], mod_bytes[i]);\n    }\n    assert_eq(max_bytes[31], mod_bytes[31] - 1);\n}\n","path":"/home/jimjim/nargo/github.com/AztecProtocol/aztec-packages/v2.0.3/noir-projects/noir-protocol-circuits/crates/types/src/utils/field.nr"},"389":{"source":"use std::hash::sha256_compression;\nuse std::runtime::is_unconstrained;\n\nuse constants::{\n    BLOCK_BYTE_PTR, BLOCK_SIZE, HASH, INITIAL_STATE, INT_BLOCK, INT_BLOCK_SIZE, INT_SIZE,\n    INT_SIZE_PTR, MSG_BLOCK, MSG_SIZE_PTR, STATE, TWO_POW_16, TWO_POW_24, TWO_POW_32, TWO_POW_8,\n};\n\npub(crate) mod constants;\nmod tests;\n\n// Implementation of SHA-256 mapping a byte array of variable length to\n// 32 bytes.\n\n// Deprecated in favour of `sha256_var`\n// docs:start:sha256\npub fn sha256<let N: u32>(input: [u8; N]) -> HASH\n// docs:end:sha256\n{\n    digest(input)\n}\n\n// SHA-256 hash function\n#[no_predicates]\npub fn digest<let N: u32>(msg: [u8; N]) -> HASH {\n    sha256_var(msg, N as u64)\n}\n\n// Variable size SHA-256 hash\npub fn sha256_var<let N: u32>(msg: [u8; N], message_size: u64) -> HASH {\n    let message_size = message_size as u32;\n    assert(message_size <= N);\n\n    if std::runtime::is_unconstrained() {\n        // Safety: SHA256 is running as an unconstrained function.\n        unsafe {\n            __sha256_var(msg, message_size)\n        }\n    } else {\n        let (mut h, mut msg_block, mut msg_byte_ptr) =\n            process_full_blocks(msg, message_size, INITIAL_STATE);\n\n        finalize_sha256_blocks(msg, message_size, N, h, msg_block, msg_byte_ptr)\n    }\n}\n\npub(crate) unconstrained fn __sha_var<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    initial_state: STATE,\n) -> HASH {\n    let num_full_blocks = message_size / BLOCK_SIZE;\n    // Intermediate hash, starting with the canonical initial value\n    let mut h: STATE = initial_state;\n    // Pointer into msg_block on a 64 byte scale\n    for i in 0..num_full_blocks {\n        let (msg_block, _) = build_msg_block(msg, message_size, BLOCK_SIZE * i);\n        h = sha256_compression(msg_block, h);\n    }\n\n    // Handle setup of the final msg block.\n    // This case is only hit if the msg is less than the block size,\n    // or our message cannot be evenly split into blocks.\n\n    finalize_last_sha256_block(h, message_size, msg)\n}\n\n// Helper function to finalize the message block with padding and length\npub(crate) unconstrained fn finalize_last_sha256_block<let N: u32>(\n    mut h: STATE,\n    message_size: u32,\n    msg: [u8; N],\n) -> HASH {\n    let modulo = message_size % BLOCK_SIZE;\n    let (mut msg_block, mut msg_byte_ptr): (INT_BLOCK, u32) = if modulo != 0 {\n        let num_full_blocks = message_size / BLOCK_SIZE;\n        let msg_start = BLOCK_SIZE * num_full_blocks;\n        let (new_msg_block, new_msg_byte_ptr) = build_msg_block(msg, message_size, msg_start);\n        (new_msg_block, new_msg_byte_ptr)\n    } else {\n        // If we had modulo == 0 then it means the last block was full,\n        // and we can reset the pointer to zero to overwrite it.\n        ([0; INT_BLOCK_SIZE], 0)\n    };\n\n    // Pad the rest such that we have a [u32; 2] block at the end representing the length\n    // of the message, and a block of 1 0 ... 0 following the message (i.e. [1 << 7, 0, ..., 0]).\n    // Here we rely on the fact that everything beyond the available input is set to 0.\n    let index = msg_byte_ptr / INT_SIZE;\n    msg_block[index] = set_item_byte_then_zeros(msg_block[index], msg_byte_ptr, 1 << 7);\n\n    // If we don't have room to write the size, compress the block and reset it.\n    let (h, mut msg_byte_ptr): (STATE, u32) = if msg_byte_ptr >= MSG_SIZE_PTR {\n        // `attach_len_to_msg_block` will zero out everything after the `msg_byte_ptr`.\n        (sha256_compression(msg_block, h), 0)\n    } else {\n        (h, msg_byte_ptr + 1)\n    };\n    msg_block = attach_len_to_msg_block(msg_block, msg_byte_ptr, message_size);\n\n    hash_final_block(msg_block, h)\n}\n\n// Variable size SHA-256 hash\nunconstrained fn __sha256_var<let N: u32>(msg: [u8; N], message_size: u32) -> HASH {\n    __sha_var(msg, message_size, INITIAL_STATE)\n}\n\npub(crate) fn process_full_blocks<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    mut h: STATE,\n) -> (STATE, MSG_BLOCK, u32) {\n    let mut msg_block: MSG_BLOCK = [0; INT_BLOCK_SIZE];\n    let mut msg_byte_ptr = 0;\n    let num_blocks = N / BLOCK_SIZE;\n    for i in 0..num_blocks {\n        let msg_start = BLOCK_SIZE * i;\n        let (new_msg_block, new_msg_byte_ptr) =\n        // Safety: separate verification function\n            unsafe { build_msg_block(msg, message_size, msg_start) };\n\n        if msg_start < message_size {\n            msg_block = new_msg_block;\n        }\n\n        // Verify the block we are compressing was appropriately constructed\n        let new_msg_byte_ptr = verify_msg_block(msg, message_size, msg_block, msg_start);\n        if msg_start < message_size {\n            msg_byte_ptr = new_msg_byte_ptr;\n        }\n\n        // If the block is filled, compress it.\n        // An un-filled block is handled after this loop.\n        if (msg_start < message_size) & (msg_byte_ptr == BLOCK_SIZE) {\n            h = sha256_compression(msg_block, h);\n        }\n    }\n    (h, msg_block, msg_byte_ptr)\n}\n\n// Take `BLOCK_SIZE` number of bytes from `msg` starting at `msg_start`.\n// Returns the block and the length that has been copied rather than padded with zeros.\npub(crate) unconstrained fn build_msg_block<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    msg_start: u32,\n) -> (MSG_BLOCK, BLOCK_BYTE_PTR) {\n    let mut msg_block: MSG_BLOCK = [0; INT_BLOCK_SIZE];\n\n    // We insert `BLOCK_SIZE` bytes (or up to the end of the message)\n    let block_input = if message_size < msg_start {\n        // This function is sometimes called with `msg_start` past the end of the message.\n        // In this case we return an empty block and zero pointer to signal that the result should be ignored.\n        0\n    } else if message_size < msg_start + BLOCK_SIZE {\n        message_size - msg_start\n    } else {\n        BLOCK_SIZE\n    };\n\n    // Figure out the number of items in the int array that we have to pack.\n    // e.g. if the input is [0,1,2,3,4,5] then we need to pack it as 2 items: [0123, 4500]\n    let int_input = (block_input + INT_SIZE - 1) / INT_SIZE;\n\n    for i in 0..int_input {\n        let mut msg_item: u32 = 0;\n        // Always construct the integer as 4 bytes, even if it means going beyond the input.\n        for j in 0..INT_SIZE {\n            let k = i * INT_SIZE + j;\n            let msg_byte = if k < block_input {\n                msg[msg_start + k]\n            } else {\n                0\n            };\n            msg_item = lshift8(msg_item, 1) + msg_byte as u32;\n        }\n        msg_block[i] = msg_item;\n    }\n\n    // Returning the index as if it was a 64 byte array.\n    // We have to project it down to 16 items and bit shifting to get a byte back if we need it.\n    (msg_block, block_input)\n}\n\n// Verify the block we are compressing was appropriately constructed by `build_msg_block`\n// and matches the input data. Returns the index of the first unset item.\n// If `message_size` is less than `msg_start` then this is called with the old non-empty block;\n// in that case we can skip verification, ie. no need to check that everything is zero.\nfn verify_msg_block<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    msg_block: MSG_BLOCK,\n    msg_start: u32,\n) -> BLOCK_BYTE_PTR {\n    let mut msg_byte_ptr = 0;\n    let mut msg_end = msg_start + BLOCK_SIZE;\n    if msg_end > N {\n        msg_end = N;\n    }\n    // We might have to go beyond the input to pad the fields.\n    if msg_end % INT_SIZE != 0 {\n        msg_end = msg_end + INT_SIZE - msg_end % INT_SIZE;\n    }\n\n    // Reconstructed packed item.\n    let mut msg_item: u32 = 0;\n\n    // Inclusive at the end so that we can compare the last item.\n    let mut i: u32 = 0;\n    for k in msg_start..=msg_end {\n        if k % INT_SIZE == 0 {\n            // If we consumed some input we can compare against the block.\n            if (msg_start < message_size) & (k > msg_start) {\n                assert_eq(msg_block[i], msg_item as u32);\n                i = i + 1;\n                msg_item = 0;\n            }\n        }\n        // Shift the accumulator\n        msg_item = lshift8(msg_item, 1);\n        // If we have input to consume, add it at the rightmost position.\n        if k < message_size & k < msg_end {\n            msg_item = msg_item + msg[k] as u32;\n            msg_byte_ptr = msg_byte_ptr + 1;\n        }\n    }\n\n    msg_byte_ptr\n}\n\n// Verify the block we are compressing was appropriately padded with zeros by `build_msg_block`.\n// This is only relevant for the last, potentially partially filled block.\nfn verify_msg_block_padding(msg_block: MSG_BLOCK, msg_byte_ptr: BLOCK_BYTE_PTR) {\n    // Check all the way to the end of the block.\n    verify_msg_block_zeros(msg_block, msg_byte_ptr, INT_BLOCK_SIZE);\n}\n\n// Verify that a region of ints in the message block are (partially) zeroed,\n// up to an (exclusive) maximum which can either be the end of the block\n// or just where the size is to be written.\nfn verify_msg_block_zeros(\n    msg_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n    max_int_byte_ptr: u32,\n) {\n    // This variable is used to get around the compiler under-constrained check giving a warning.\n    // We want to check against a constant zero, but if it does not come from the circuit inputs\n    // or return values the compiler check will issue a warning.\n    let zero = msg_block[0] - msg_block[0];\n\n    // First integer which is supposed to be (partially) zero.\n    let mut int_byte_ptr = msg_byte_ptr / INT_SIZE;\n\n    // Check partial zeros.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        let zeros = INT_SIZE - modulo;\n        let mask = if zeros == 3 {\n            TWO_POW_24\n        } else if zeros == 2 {\n            TWO_POW_16\n        } else {\n            TWO_POW_8\n        };\n        assert_eq(msg_block[int_byte_ptr] % mask, zero);\n        int_byte_ptr = int_byte_ptr + 1;\n    }\n\n    // Check the rest of the items.\n    for i in 0..max_int_byte_ptr {\n        if i >= int_byte_ptr {\n            assert_eq(msg_block[i], zero);\n        }\n    }\n}\n\n// Verify that up to the byte pointer the two blocks are equal.\n// At the byte pointer the new block can be partially zeroed.\nfn verify_msg_block_equals_last(\n    msg_block: MSG_BLOCK,\n    last_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n) {\n    // msg_byte_ptr is the position at which they are no longer have to be the same.\n    // First integer which is supposed to be (partially) zero contains that pointer.\n    let mut int_byte_ptr = msg_byte_ptr / INT_SIZE;\n\n    // Check partial zeros.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        // Reconstruct the partially zero item from the last block.\n        let last_field = last_block[int_byte_ptr];\n        let mut msg_item: u32 = 0;\n        // Reset to where they are still equal.\n        msg_byte_ptr = msg_byte_ptr - modulo;\n        for i in 0..INT_SIZE {\n            msg_item = lshift8(msg_item, 1);\n            if i < modulo {\n                msg_item = msg_item + get_item_byte(last_field, msg_byte_ptr) as u32;\n                msg_byte_ptr = msg_byte_ptr + 1;\n            }\n        }\n        assert_eq(msg_block[int_byte_ptr], msg_item);\n    }\n\n    for i in 0..INT_SIZE_PTR {\n        if i < int_byte_ptr {\n            assert_eq(msg_block[i], last_block[i]);\n        }\n    }\n}\n\n// Set the rightmost `zeros` number of bytes to 0.\n#[inline_always]\nfn set_item_zeros(item: u32, zeros: u32) -> u32 {\n    lshift8(rshift8(item, zeros), zeros)\n}\n\n// Replace one byte in the item with a value, and set everything after it to zero.\nfn set_item_byte_then_zeros(msg_item: u32, msg_byte_ptr: BLOCK_BYTE_PTR, msg_byte: u8) -> u32 {\n    let zeros = INT_SIZE - msg_byte_ptr % INT_SIZE;\n    let zeroed_item = set_item_zeros(msg_item, zeros);\n    let new_item = byte_into_item(msg_byte, msg_byte_ptr);\n    zeroed_item + new_item\n}\n\n// Get a byte of a message item according to its overall position in the `BLOCK_SIZE` space.\nfn get_item_byte(mut msg_item: u32, msg_byte_ptr: BLOCK_BYTE_PTR) -> u8 {\n    // How many times do we have to shift to the right to get to the position we want?\n    let max_shifts = INT_SIZE - 1;\n    let shifts = max_shifts - msg_byte_ptr % INT_SIZE;\n    msg_item = rshift8(msg_item, shifts);\n    // At this point the byte we want is in the rightmost position.\n    msg_item as u8\n}\n\n// Project a byte into a position in a field based on the overall block pointer.\n// For example putting 1 into pointer 5 would be 100, because overall we would\n// have [____, 0100] with indexes [0123,4567].\n#[inline_always]\nfn byte_into_item(msg_byte: u8, msg_byte_ptr: BLOCK_BYTE_PTR) -> u32 {\n    let mut msg_item = msg_byte as u32;\n    // How many times do we have to shift to the left to get to the position we want?\n    let max_shifts = INT_SIZE - 1;\n    let shifts = max_shifts - msg_byte_ptr % INT_SIZE;\n    lshift8(msg_item, shifts)\n}\n\n// Construct a field out of 4 bytes.\n#[inline_always]\nfn make_item(b0: u8, b1: u8, b2: u8, b3: u8) -> u32 {\n    let mut item = b0 as u32;\n    item = lshift8(item, 1) + b1 as u32;\n    item = lshift8(item, 1) + b2 as u32;\n    item = lshift8(item, 1) + b3 as u32;\n    item\n}\n\n// Shift by 8 bits to the left between 0 and 4 times.\n// Checks `is_unconstrained()` to just use a bitshift if we're running in an unconstrained context,\n// otherwise multiplies by 256.\n#[inline_always]\nfn lshift8(item: u32, shifts: u32) -> u32 {\n    if is_unconstrained() {\n        // Brillig wouldn't shift 0<<4 without overflow.\n        if shifts >= 4 {\n            0\n        } else {\n            item << (8 * shifts)\n        }\n    } else {\n        // We can do a for loop up to INT_SIZE or an if-else.\n        if shifts == 0 {\n            item\n        } else if shifts == 1 {\n            item * TWO_POW_8\n        } else if shifts == 2 {\n            item * TWO_POW_16\n        } else if shifts == 3 {\n            item * TWO_POW_24\n        } else {\n            // Doesn't make sense, but it's most likely called on 0 anyway.\n            0\n        }\n    }\n}\n\n// Shift by 8 bits to the right between 0 and 4 times.\n// Checks `is_unconstrained()` to just use a bitshift if we're running in an unconstrained context,\n// otherwise divides by 256.\n#[inline_always]\nfn rshift8(item: u32, shifts: u32) -> u32 {\n    if is_unconstrained() {\n        if 8 * shifts >= 32 {\n            0\n        } else {\n            item >> (8 * shifts)\n        }\n    } else {\n        // Division wouldn't work on `Field`.\n        if shifts == 0 {\n            item\n        } else if shifts == 1 {\n            item / TWO_POW_8\n        } else if shifts == 2 {\n            item / TWO_POW_16\n        } else if shifts == 3 {\n            item / TWO_POW_24\n        } else {\n            0\n        }\n    }\n}\n\n// Zero out all bytes between the end of the message and where the length is appended,\n// then write the length into the last 8 bytes of the block.\nunconstrained fn attach_len_to_msg_block(\n    mut msg_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n    message_size: u32,\n) -> MSG_BLOCK {\n    // We assume that `msg_byte_ptr` is less than 57 because if not then it is reset to zero before calling this function.\n    // In any case, fill blocks up with zeros until the last 64 bits (i.e. until msg_byte_ptr = 56).\n    // There can be one item which has to be partially zeroed.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        // Index of the block in which we find the item we need to partially zero.\n        let i = msg_byte_ptr / INT_SIZE;\n        let zeros = INT_SIZE - modulo;\n        msg_block[i] = set_item_zeros(msg_block[i], zeros);\n        msg_byte_ptr = msg_byte_ptr + zeros;\n    }\n\n    // The rest can be zeroed without bit shifting anything.\n    for i in (msg_byte_ptr / INT_SIZE)..INT_SIZE_PTR {\n        msg_block[i] = 0;\n    }\n\n    // Set the last two 4 byte ints as the first/second half of the 8 bytes of the length.\n    let len = 8 * message_size;\n    let len_bytes: [u8; 8] = (len as Field).to_be_bytes();\n    msg_block[INT_SIZE_PTR] = (len_bytes[0] as u32) << 24\n        | (len_bytes[1] as u32) << 16\n        | (len_bytes[2] as u32) << 8\n        | (len_bytes[3] as u32);\n\n    msg_block[INT_SIZE_PTR + 1] = (len_bytes[4] as u32) << 24\n        | (len_bytes[5] as u32) << 16\n        | (len_bytes[6] as u32) << 8\n        | (len_bytes[7] as u32);\n\n    msg_block\n}\n\n// Verify that the message length was correctly written by `attach_len_to_msg_block`,\n// and that everything between the byte pointer and the size pointer was zeroed,\n// and that everything before the byte pointer was untouched.\nfn verify_msg_len(\n    msg_block: MSG_BLOCK,\n    last_block: MSG_BLOCK,\n    msg_byte_ptr: BLOCK_BYTE_PTR,\n    message_size: u32,\n) {\n    // Check zeros up to the size pointer.\n    verify_msg_block_zeros(msg_block, msg_byte_ptr, INT_SIZE_PTR);\n\n    // Check that up to the pointer we match the last block.\n    verify_msg_block_equals_last(msg_block, last_block, msg_byte_ptr);\n\n    // We verify the message length was inserted correctly by reversing the byte decomposition.\n    std::static_assert(\n        INT_SIZE_PTR + 2 == INT_BLOCK_SIZE,\n        \"INT_SIZE_PTR + 2 must equal INT_BLOCK_SIZE\",\n    );\n    let reconstructed_len_hi = msg_block[INT_SIZE_PTR] as Field;\n    let reconstructed_len_lo = msg_block[INT_SIZE_PTR + 1] as Field;\n\n    let reconstructed_len: Field =\n        reconstructed_len_hi * TWO_POW_32 as Field + reconstructed_len_lo;\n    let len = 8 * (message_size as Field);\n    assert_eq(reconstructed_len, len);\n}\n\n// Perform the final compression, then transform the `STATE` into `HASH`.\nfn hash_final_block(msg_block: MSG_BLOCK, mut state: STATE) -> HASH {\n    let mut out_h: HASH = [0; 32]; // Digest as sequence of bytes\n    // Hash final padded block\n    state = sha256_compression(msg_block, state);\n\n    // Return final hash as byte array\n    for j in 0..8 {\n        let h_bytes: [u8; 4] = (state[j] as Field).to_be_bytes();\n        for k in 0..4 {\n            out_h[4 * j + k] = h_bytes[k];\n        }\n    }\n\n    out_h\n}\n\npub(crate) fn finalize_sha256_blocks<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    total_len: u32,\n    mut h: STATE,\n    mut msg_block: MSG_BLOCK,\n    mut msg_byte_ptr: u32,\n) -> HASH {\n    let modulo = total_len % BLOCK_SIZE;\n    // Handle setup of the final msg block.\n    // This case is only hit if the msg is less than the block size,\n    // or our message cannot be evenly split into blocks.\n    if modulo != 0 {\n        let num_blocks = total_len / BLOCK_SIZE;\n        let msg_start = BLOCK_SIZE * num_blocks;\n        let (new_msg_block, new_msg_byte_ptr) =\n        // Safety: separate verification function\n            unsafe { build_msg_block(msg, message_size, msg_start) };\n\n        if msg_start < message_size {\n            msg_block = new_msg_block;\n        }\n\n        let new_msg_byte_ptr = verify_msg_block(msg, message_size, msg_block, msg_start);\n        if msg_start < message_size {\n            msg_byte_ptr = new_msg_byte_ptr;\n            verify_msg_block_padding(msg_block, msg_byte_ptr);\n        }\n    }\n\n    // If we had modulo == 0 then it means the last block was full,\n    // and we can reset the pointer to zero to overwrite it.\n    if msg_byte_ptr == BLOCK_SIZE {\n        msg_byte_ptr = 0;\n    }\n\n    // Pad the rest such that we have a [u32; 2] block at the end representing the length\n    // of the message, and a block of 1 0 ... 0 following the message (i.e. [1 << 7, 0, ..., 0]).\n    // Here we rely on the fact that everything beyond the available input is set to 0.\n    let index = msg_byte_ptr / INT_SIZE;\n    msg_block[index] = set_item_byte_then_zeros(msg_block[index], msg_byte_ptr, 1 << 7);\n\n    msg_byte_ptr = msg_byte_ptr + 1;\n    let last_block = msg_block;\n\n    // If we don't have room to write the size, compress the block and reset it.\n    if msg_byte_ptr > MSG_SIZE_PTR {\n        h = sha256_compression(msg_block, h);\n\n        // `attach_len_to_msg_block` will zero out everything after the `msg_byte_ptr`.\n        msg_byte_ptr = 0;\n    }\n\n    // Safety: separate verification function\n    msg_block = unsafe { attach_len_to_msg_block(msg_block, msg_byte_ptr, message_size) };\n\n    verify_msg_len(msg_block, last_block, msg_byte_ptr, message_size);\n\n    hash_final_block(msg_block, h)\n}\n\n/**\n * Given some state of a partially computed sha256 hash and part of the preimage, continue hashing\n * @notice used for complex/ recursive offloading of post-partial hashing\n *\n * @param N - the maximum length of the message to hash\n * @param h - the intermediate hash state\n * @param msg - the preimage to hash\n * @param message_size - the actual length of the preimage to hash\n * @return the intermediate hash state after compressing in msg to h\n */\npub fn partial_sha256_var_interstitial<let N: u32>(\n    mut h: [u32; 8],\n    msg: [u8; N],\n    message_size: u32,\n) -> [u32; 8] {\n    assert(message_size % BLOCK_SIZE == 0, \"Message size must be a multiple of the block size\");\n    if std::runtime::is_unconstrained() {\n        // Safety: running as an unconstrained function\n        unsafe {\n            __sha_partial_var_interstitial(h, msg, message_size)\n        }\n    } else {\n        let (mut h, _, _) = process_full_blocks(msg, message_size, h);\n\n        h\n    }\n}\n\n/**\n * Given some state of a partially computed sha256 hash and remaining preimage, complete the hash\n * @notice used for traditional partial hashing\n *\n * @param N - the maximum length of the message to hash\n * @param h - the intermediate hash state\n * @param msg - the remaining preimage to hash\n * @param message_size - the size of the current chunk\n * @param real_message_size - the total size of the original preimage\n * @return finalized sha256 hash\n */\npub fn partial_sha256_var_end<let N: u32>(\n    mut h: [u32; 8],\n    msg: [u8; N],\n    message_size: u32,\n    real_message_size: u32,\n) -> [u8; 32] {\n    assert(message_size % BLOCK_SIZE == 0, \"Message size must be a multiple of the block size\");\n    if std::runtime::is_unconstrained() {\n        // Safety: running as an unconstrained function\n        unsafe {\n            h = __sha_partial_var_interstitial(h, msg, message_size);\n\n            // Handle setup of the final msg block.\n            // This case is only hit if the msg is less than the block size,\n            // or our message cannot be evenly split into blocks.\n\n            finalize_last_sha256_block(h, real_message_size, msg)\n        }\n    } else {\n        let (mut h, mut msg_block, mut msg_byte_ptr) = process_full_blocks(msg, message_size, h);\n        finalize_sha256_blocks(msg, real_message_size, N, h, msg_block, msg_byte_ptr)\n    }\n}\n\nunconstrained fn __sha_partial_var_interstitial<let N: u32>(\n    mut h: [u32; 8],\n    msg: [u8; N],\n    message_size: u32,\n) -> [u32; 8] {\n    let num_full_blocks = message_size / BLOCK_SIZE;\n    // Intermediate hash, starting with the canonical initial value\n    // Pointer into msg_block on a 64 byte scale\n    for i in 0..num_full_blocks {\n        let (msg_block, _) = build_msg_block(msg, message_size, BLOCK_SIZE * i);\n        h = sha256_compression(msg_block, h);\n    }\n    h\n}\n\nmod equivalence_test {\n\n    #[test]\n    fn test_implementations_agree(msg: [u8; 100], message_size: u64) {\n        let message_size = message_size % 100;\n        // Safety: test function\n        let unconstrained_sha = unsafe { super::__sha256_var(msg, message_size as u32) };\n        let sha = super::sha256_var(msg, message_size);\n        assert_eq(sha, unconstrained_sha);\n    }\n}\n","path":"/home/jimjim/nargo/github.com/noir-lang/sha256/v0.2.0/src/sha256.nr"}}}